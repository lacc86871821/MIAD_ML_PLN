{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de árboles de decisión y métodos de ensamblaje\n",
    "\n",
    "En este taller podrá poner en práctica los sus conocimientos sobre construcción e implementación de árboles de decisión y métodos de ensamblajes. El taller está constituido por 9 puntos, 5 relacionados con árboles de decisión (parte A) y 4 con métodos de ensamblaje (parte B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Árboles de decisión\n",
    "\n",
    "En esta parte del taller se usará el conjunto de datos de Capital Bikeshare de Kaggle, donde cada observación representa el alquiler de una bicicleta durante una hora y día determinado. Para más detalles puede visitar los siguientes enlaces: [datos](https://github.com/justmarkham/DAT8/blob/master/data/bikeshare.csv), [dicccionario de datos](https://www.kaggle.com/c/bike-sharing-demand/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos prestamo de bicicletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>total</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather  temp   atemp  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  total  hour  \n",
       "datetime                                                                   \n",
       "2011-01-01 00:00:00        81        0.0       3          13     16     0  \n",
       "2011-01-01 01:00:00        80        0.0       8          32     40     1  \n",
       "2011-01-01 02:00:00        80        0.0       5          27     32     2  \n",
       "2011-01-01 03:00:00        75        0.0       3          10     13     3  \n",
       "2011-01-01 04:00:00        75        0.0       0           1      1     4  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "bikes = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "# Renombrar variable \"count\" a \"total\"\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "# Crear la hora como una variable \n",
    "bikes['hour'] = bikes.index.hour\n",
    "# Visualización\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Análisis descriptivo\n",
    "\n",
    "Ejecute las celdas 1.1 y 1.2. A partir de los resultados realice un análisis descriptivo sobre las variables hour y workingday, escriba sus inferencias sobre los datos. Para complementar su análisis puede usar métricas como máximo, mínimo, percentiles entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workingday\n",
       "0    188.506621\n",
       "1    193.011873\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.1\n",
    "bikes.groupby('workingday').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0      55.138462\n",
       "1      33.859031\n",
       "2      22.899554\n",
       "3      11.757506\n",
       "4       6.407240\n",
       "5      19.767699\n",
       "6      76.259341\n",
       "7     213.116484\n",
       "8     362.769231\n",
       "9     221.780220\n",
       "10    175.092308\n",
       "11    210.674725\n",
       "12    256.508772\n",
       "13    257.787281\n",
       "14    243.442982\n",
       "15    254.298246\n",
       "16    316.372807\n",
       "17    468.765351\n",
       "18    430.859649\n",
       "19    315.278509\n",
       "20    228.517544\n",
       "21    173.370614\n",
       "22    133.576754\n",
       "23     89.508772\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.2\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Análisis de gráficos\n",
    "\n",
    "Primero ejecute la celda 2.1 y asegúrese de comprender el código y el resultado. Luego, en cada una de celdas 2.2 y 2.3 escriba un código que genere una gráfica de las rentas promedio por hora cuando la variable \"workingday\" es igual a 0 e igual a 1, respectivamente. Analice y escriba sus hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.1 - rentas promedio para cada valor de la variable \"hour\"\n",
    "bikes.groupby(by='hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtTElEQVR4nO3deXxV1bn/8c+TOSETgZARSIAAMiNhEqQIWtGqYJ3AoThdeqve2uHXqvfX8d7b363ttba21dYRvFrBAQWttSqgODAkzDOEISQhZCAkBMic5/dHNjVFIIHkZJ/heb9eeWWftffJeXI8+bpZe+21RFUxxhjjX4LcLsAYY0zns3A3xhg/ZOFujDF+yMLdGGP8kIW7Mcb4IQt3Y4zxQyHtPVBEgoFcoEhVrxGRTGAh0ANYB9yhqvUiEg68CIwBjgC3qOqBc/3snj17akZGxoX9BsYYE6DWrVtXrqqJZ9rX7nAHHgR2ALHO40eBx1V1oYj8CbgHeMr5flRVB4jIbOe4W871gzMyMsjNzT2PUowxxohI/tn2tatbRkTSga8BzzqPBZgGvO4csgCY5WzPdB7j7J/uHG+MMaaLtLfP/bfAD4Fm53EPoFJVG53HhUCas50GFAA4+6uc440xxnSRNsNdRK4BSlV1XWe+sIjME5FcEcktKyvrzB9tjDEBrz1n7pOA60TkAC0XUKcBvwPiReRUn306UORsFwG9AZz9cbRcWP0nqvq0qmaranZi4hmvBxhjjLlAbYa7qj6iqumqmgHMBpar6m3ACuBG57C5wBJne6nzGGf/crXZyYwxpkt1ZJz7Q8D3RCSPlj7155z254AeTvv3gIc7VqIxxpjzdT5DIVHVj4CPnO19wLgzHFML3NQJtRljjLlAdoeqMV2guVlZl1/Bs5/sY+fhY26XYwLAeZ25G2PaT1XZdugYb286xDubiymqrPnHvsHJMcwancZ1I1NJjY90sUrjr8QbrnVmZ2er3aFq/MXukup/BPr+8hOEBAlTBiZyzYgUxmYk8NGuUt7cUMT6g5WIwPjMBK4fncaMYSnERYa6Xb7xISKyTlWzz7jPwt2YjjtQfoJ3Nh/i7U3F7CqpJkhgYv8eXDsilRnDkomPCvvSc/KPnGDJxkO8taGIfeUnCAsJYvrgXswancbUQYmEhwS78JsYX2LhbowHFFXW8Fcn0LcUVQEwNqM7145M5aphKSTGhLfr56gqmwureGtjEW9vOkT58XriIkO5engK149OI7tvd4KCbAYP82UW7sZ0sv9ddYAfL9kGwMj0OK4ZkcrXRqR0uP+8samZT/PKWbLxEO9tPUxNQxNp8ZFM6NeD4WmxDE+P46KUWKLC7HKZsXA3plPV1Dcx6dHlDEiM5tc3jaBvj24eeZ0TdY18sL2EdzYXs7GgkvLjdQAECfRPjGZ4WhxD0+IYnhbHkNRYosMt8APNucLdPg3GnKeFOQepOFHPD+4Y5LFgB+gWHsKs0WnMGp2GqlJaXceWwiq2FFWxtaiKT/PKWbyhZdYPEcjs2Y3hTtgPTY1jeHqcBX4As//yxpyH+sZmnlm5j7EZ3RmbkdBlrysiJMVGkDQkgsuHJP2jvfRYLVsPVbGl8BhbiqpYu7+CJRsPARAcJAxJiWVsRgLjMlvq7RHdvusAxvdZuBtzHpZsLOJQVS2/uH6426UA0Cs2gmmxEUwb/EXgl1XXsfVQFevzj7J2fwUvrcnn+c/2A9AvsRvjMxMYm9Hyld49EltuwT9ZuBvTTs3Nyp8+3stFKbFMHeS9M5kmxoRz2aBeXDaoFwB1jU1sKaxi7YEKcvZX8M7mYl5ZWwBASlxES9BnJjAuI4GsXtE2MsdPWLgb007vbz/M3rITPDFntE+d7YaHBJOdkUB2RgJMhaZmZdfhanIOVLD2QAWr9x1h6aaWrpxBSTG8Mm8CCd2+PC7f+BYLd2PaQVV58qO99O0RxdXDkt0up0OCg4QhqbEMSY1l7iUZqCoHK07yyZ5y/vOd7dw9P4dX/mUCkWF2E5Uvs4nDjGmHz/KOsLmwim9O6U9IsH/92YgIfXt04/YJffnd7NFsKqzk317ZQGNTc9tPNl7Lvz6lxnjIkx/l0SsmnBvGpLV9sA+bMSyZn107lA93lPDjJdvwhvtgzIWxbhlj2rCxoJLP9x7h368eHBDzvcy9JIPDx2p56qO9pMZF8G/Ts9wuyVwAC3dj2vDkijziIkO5dXxft0vpMj+8chAlVbU89sFukuIiuDm7t9slmfPUZreMiESIyFoR2SQi20Tk5077fBHZLyIbna9RTruIyBMikicim0XkYg//DsZ4zJ6Sat7fXsLciX0D6m5PEeGXN4zg0qyePLJ4Cyt2lbpdkjlP7elzrwOmqepIYBQwQ0QmOPt+oKqjnK+NTttVQJbzNQ94qnNLNqbrPPXxXiJDg7lzUqbbpXS5sJAgnrp9DIOTY7j/5fVsLqx0uyRzHtoMd21x3HkY6nyd6yrLTOBF53mrgXgRSel4qcZ0rcKjJ1m68RCzx/UO2HHf0eEhvHDXWBK6hXH3/Bzyj5xwuyTTTu0aLSMiwSKyESgFPlDVNc6uXzhdL4+LyKlJK9KAglZPL3TajPEpz6zchwj8y6X93C7FVb1iIlhw9zgam5W5z6/liDM7pfFu7Qp3VW1S1VFAOjBORIYBjwCDgbFAAvDQ+bywiMwTkVwRyS0rKzu/qo3xsPLjdSzMKWDWqDRb45SWKYafmzuW4qpa7l6Qy8n6RrdLMm04r3HuqloJrABmqGqx0/VSB7wAjHMOKwJaX1pPd9pO/1lPq2q2qmYnJnrvPB0mMM3/7AD1Tc3869T+bpfiNcb07c7v54xmS2ElD/zFbnLydu0ZLZMoIvHOdiRwBbDzVD+6tEyyMQvY6jxlKfANZ9TMBKBKVYs9ULsxHlFd28CCVQeYMTSZ/onRbpfjVb46NJn/mDmM5TtL+dFbW+0mJy/WnrFdKcACEQmm5X8Gr6rqOyKyXEQSAQE2Av/qHP8ucDWQB5wE7ur0qo3xoJfXHKS6tpH7pg5wuxSvdPuEvhyuquUPK/JIiYvkwcvtJidv1Ga4q+pmYPQZ2qed5XgF7u94acZ0vdqGJp77dD+XZvVkeHqc2+V4re9/dSDFVbU8/uFukuPCuWVsH7dLMqexuWWMaeX1dYWUVdfxLetrP6eWm5yGM2VgIv/+5lZ2FB9zuyRzGgt3YxyNTc38eeVeRvWOZ2K/Hm6X4/VCg4P4/ezRdAsL5tH3drpdjjmNhbsxjr9uKaagoob7pvb3qcU43BQXFcr9lw3go11lfL633O1yTCsW7sbQshjHUx/tJatXNJdflNT2E8w/zL0kg9S4CH75t502esaLWLgbAyzfWcrOw9V8a2p/W0P0PEWEBvPdKwayubCKv26xUc/ewsLdBLxTS+ilxUdy7chUt8vxSV+/OJ3ByTH8+u+7qG+0m5u8gYW7CXhr91ewLv8o3/xKP0L9bAm9rhIcJDw0YzD5R06yMOeg2+UYLNyN4U8f76VndJgtSNFBUwclMj4zgd99uIfjdTb3jNss3E1Ayz9ygo92l3Hb+L5EhPr/EnqeJCI8cvVFHDlRz9Mr97ldTsCzcDcB7S9rDhIkwq3j7Q7LzjCqdzxfG57Cs5/so7S61u1yApqFuwlYtQ1NvJpbwFeHJJEUG+F2OX7j/1w5iPrGZp5YtsftUgKahbsJWO9uKeboyQbumBA4C193hcye3Zgzrg+vrC1gX9nxtp9gPMLC3QSsl1bn0y+xGxP721QDne3b07OICAnif97f5XYpAcvC3QSkrUVVrD9Yye3j+9pUAx6QGBPOv0zpx7tbDrPh4FG3ywlIFu4mIL28Jp+I0CBuGJPudil+695L+9EzOoz/tmkJXGHhbgLOsdoG3tpwiJkj04iLDHW7HL8VHR7Cg9OzWLu/ghW7St0uJ+BYuJuAs3hdITUNTdxuF1I9bva4PmT0iOLRv+2iqdnO3rtSe9ZQjRCRtSKySUS2icjPnfZMEVkjInkiskhEwpz2cOdxnrM/w8O/gzHtpqq8tOYgI3vH20pLXSA0OIgfXDmYXSXVvLG+0O1yAkp7ztzrgGmqOhIYBcxwFr5+FHhcVQcAR4F7nOPvAY467Y87xxnjFVbvqyCv9Di3201LXebq4cmM7B3P4x/sprahye1yAkab4a4tTg1WDXW+FJgGvO60LwBmOdszncc4+6eLDUcwXuKlNfnERYba7I9dSER45KrBFFfVMv/zA26XEzDa1ecuIsEishEoBT4A9gKVqnpqdqBCIM3ZTgMKAJz9VYANJDauKz1Wy9+3Hubm7HSbR6aLTejXg8sGJfLkijwqT9a7XU5AaFe4q2qTqo4C0oFxwOCOvrCIzBORXBHJLSsr6+iPM6ZNi3IKaGxWbh1vF1Ld8NBVg6mua+TJj/a6XUpAOK/RMqpaCawAJgLxIhLi7EoHipztIqA3gLM/Djhyhp/1tKpmq2p2YmLihVVvTDs1NjXzl7UHuTSrJ5k9u7ldTkAanBzLDRenM//zAxRV1rhdjt9rz2iZRBGJd7YjgSuAHbSE/I3OYXOBJc72Uucxzv7lancwGJct31lKcVWtDX902XevGAjAb97f7XIl/q89Z+4pwAoR2QzkAB+o6jvAQ8D3RCSPlj7155zjnwN6OO3fAx7u/LKNOT//uzqflLgIpg/u5XYpAS0tPpK7Lslg8YZCdhQfc7scvxbS1gGquhkYfYb2fbT0v5/eXgvc1CnVGdMJDpSf4JM95XzvioGE2DJ6rrtv6gD+svYgj3+wm6e/ke12OX7LPunG7728Jp+QIGH2WFtGzxvERYVy7+R+vL+9hC2FVW6X47cs3I1fq21o4rV1hVw5NJletiCH17h7cgZxkaH89kPre/cUC3fj197ZXEzlyQa7kOplYiJCmTelH8t2ltqUwB5i4W782v+uzmdAr2gm9EtwuxRzmrmXZJDQLYzHP7Tl+DzBwt34rS2FVWwqqOT28X1sQQ4vFB0ewjen9GPl7jJyD1S4XY7fsXA3fuul1flEhgbzdVuQw2t9Y2IGPaPDedz63judhbvxS1U1DSzZVMSs0anERtiCHN4qMiyYb03tz2d5R1i970s3spsOsHA3fumNdYXUNjTbhVQfcNv4PvSKCec3H+y25fg6kYW78TstC3LkM7pPPENTbUEObxcRGsz9lw1g7f4KPt9rZ++dxcLd+J1Ve4+wr+wEd9hZu8+YPa43KXERdvbeiSzcjd95aU0+3aNCuXp4itulmHYKDwnmgWkDWJd/lI932xTgncHC3fiVkmO1/H1bCTdn97YFOXzMTWN6kxYfyeN29t4pLNyNX1m4toCmZuVWWyPV54SFBPHt6QPYVFjF8p2lbpfj8yzcjd9oalZeWXuQrwxMpG8PW5DDF3394nT69oiyvvdOYOFu/MamwkoOH6vl6xentX2w8UqhwUF8e1oW2w4d4+/bStwux6dZuBu/sXxHKcFBwlcG2rKNvmzmqFT69ezGbz/cTXOznb1fKAt34zeW7yxlTN/uxEeFuV2K6YCQ4CAevDyLnYer+dvWw26X47Pas4ZqbxFZISLbRWSbiDzotP9MRIpEZKPzdXWr5zwiInkisktErvTkL2AMQHFVDduLjzHNltHzC9eMSCWrVzS//XA3TXb2fkHac+beCHxfVYcAE4D7RWSIs+9xVR3lfL0L4OybDQwFZgBPioiNSTMedWp0ha2R6h+Cg4TvXD6QPaXHeWfzIbfL8UlthruqFqvqeme7GtgBnOuK1UxgoarWqep+II8zrLVqTGdasbOU3gmRDOgV7XYpppNcNSyZwckx/O7DPTQ2Nbtdjs85rz53EcmgZbHsNU7TAyKyWUSeF5HuTlsaUNDqaYWc+38GxnRIbUMTn+aVM31wks3b7keCnLP3feUnWLLRzt7PV7vDXUSigTeA76jqMeApoD8wCigGHjufFxaReSKSKyK5ZWV2u7G5cKv2HqG2oZnLrEvG71w5NImhqbE8sXwPDXb2fl7aFe4iEkpLsL+sqosBVLVEVZtUtRl4hi+6XoqA1svMpztt/0RVn1bVbFXNTky0oWvmwi3fWUpUWDDjM20pPX8jInzvioHkHznJ4vWFbpfjU9ozWkaA54AdqvqbVu2tZ2W6HtjqbC8FZotIuIhkAlnA2s4r2ZgvqCrLd5YyeUBPm0vGT00b3IuR6XE8sSyP+kY7e2+v9py5TwLuAKadNuzxVyKyRUQ2A5cB3wVQ1W3Aq8B24D3gflVt8kz5JtDtKqmmqLLGhkD6MRHhu1cMpKiyhtfWFbT9BANASFsHqOqnwJmuUr17juf8AvhFB+oypl2W7WgZAmn97f7tKwMTGdk7nmc/2c+csX0ICrIL522xO1SNT1uxs5ThaXEkxUa4XYrxIBHh7kkZ7C8/YfO9t5OFu/FZFSfqWX/wqJ21B4irh6eQFBvO85/td7sUn2DhbnzWx7tLaVa7KzVQhAYHcceEvnyyp5y80mq3y/F6Fu7GZy3fWUbP6HCGp9ki2IFizrg+hIUE8cJnB9wuxetZuBuf1NDUzMe7SrlsUKJdXAsgPaLDmTUqlcXri6g62eB2OV7Nwt34pHX5RzlW28j0i6xLJtDcNSmTmoYmFuYcdLsUr2bhbnzSip2lhAYLk7Ps7uZAc1FKLBP6JfDiqnybUOwcLNyNT1q2s5TxmT2IDm/zVg3jh+6alElRZQ0fbLel+M7Gwt34nINHTpJXetzuSg1gl1+URO+ESBsWeQ4W7sbnLN/ZcrZm/e2BKzhImDsxg5wDR9laVOV2OV7Jwt34nGU7S+mf2I2+Pbq5XYpx0U3ZvYkKC7az97OwcDc+5XhdI2v2VViXjCEuMpQbx6TzzqZiyqrr3C7H61i4G5/y6Z5y6puamTY4ye1SjBeYe0kG9U3NvLwm3+1SvI6Fu/EpK3aWEhMRQnZG97YPNn6vf2I0Uwcl8tLqg9Q12szirVm4G5/R3Kws31XKlIGJhAbbR9e0uGtSJuXH6/jr5mK3S/Eq9hdifMbWQ1WUVdfZRGHmn0zJ6kn/xG688NkBVNXtcryGhbvxGct3liICUwdZuJsviAh3TspkS1EV6/KPul2O12jPGqq9RWSFiGwXkW0i8qDTniAiH4jIHud7d6ddROQJEckTkc0icrGnfwkTGJbvLGV073gSuoW5XYrxMjdcnEZsRIjNFtlKe87cG4Hvq+oQYAJwv4gMAR4GlqlqFrDMeQxwFS2LYmcB84CnOr1qE3BKj9WyubCK6RfZKBnzZVFhIcwZ14f3th3mUGWN2+V4hTbDXVWLVXW9s10N7ADSgJnAAuewBcAsZ3sm8KK2WA3Ei0hKZxduAstHu1qWVrPx7eZs7pjYF1XlxVU2LBLOs89dRDKA0cAaIElVT12ePgycOqVKA1ovUV7otBlzwZbtLCElLoLByTFul2K8VHr3KK4cmswraw9SU2/DItsd7iISDbwBfEdVj7Xepy2XqM/rMrWIzBORXBHJLSuzBW/N2dU1NvHJnnKmDe6FiC3MYc7urkmZVNU08OaGIrdLcV27wl1EQmkJ9pdVdbHTXHKqu8X5Xuq0FwG9Wz093Wn7J6r6tKpmq2p2YqLNyW3Obu3+Ck7WN9lEYaZNYzO6MzQ1lvmf7w/4YZHtGS0jwHPADlX9TatdS4G5zvZcYEmr9m84o2YmAFWtum+MOW/LdpQSHhLExH493S7FeDkR4a5JmewuOc5neUfcLsdV7TlznwTcAUwTkY3O19XAL4ErRGQPcLnzGOBdYB+QBzwD3Nf5ZZtAoaos21nCpAE9iQwLdrsc4wOuHZlCz+gwXgjw2SLbXMZGVT8FztbROf0MxytwfwfrMgaAvWXHKaio4ZtT+rtdivER4SHB3Dq+L79fvocD5SfI6BmYU0PbHarGqy3f2XIpx4ZAmvNx+4Q+hAQJ8z8/4HYprrFwN15t2Y5SBifHkBof6XYpxof0iongmhGpvL6ukOraBrfLcYWFu/FaVScbyM0/aqNkzAW5a1IGx+saeS230O1SXGHhbrzWyj1lNDWrLcxhLsiI9HjG9O3On1fupfJkvdvldDkLd+O1lu8sJaFbGKN6x7tdivFRP79uKBUn6nnojc0BN+7dwt14paZm5aNdpUwdmEhwkN2Vai7MsLQ4fnjlYP6+rYS/rD3odjldysLdeKWcAxUcPdnAZTZKxnTQPZMzuTSrJ//x9nZ2l1S7XU6XsXA3Xum13EKiw0PsYqrpsKAg4bGbRxITEcK3X9lAbUNgTCpm4W68TnVtA+9uKebakSlEhbV5n50xbeoVE8H/3DSSnYer+e93d7hdTpewcDde5+1NxdQ0NHFzdu+2DzamnaYO6sU9kzNZsCqfD7eXuF2Ox1m4G6+zKLeAgUnRNkrGdLofzhjE0NRYfvD6Jg5X1bpdjkdZuBuvsutwNZsKKrk5u7fN3W46XXhIME/MGU1tQzPfe3UjTc3+OzzSwt14lUU5BYQGC1+/ON3tUoyf6p8Yzc+vG8rne4/w55V73S7HYyzcjdeoa2zizQ2FXDEkiYRuYW6XY/zYTdnpfG1ECo+9v5sNB4+6XY5HWLgbr/Hh9lKOnmywC6nG40SE/3f9cJJjI/j2wg1+ObmYhbvxGotyC0iNi+DSLFt20XheXGQoT8wZxaHKWn701la/m57Awt14haLKGj7ZU8aNY9JtugHTZcb0TeDB6Vks2XiIxev9a1Ht9qyh+ryIlIrI1lZtPxORotOW3Tu17xERyRORXSJypacKN/7l9dxCVOEm65IxXez+ywYwLjOBnyzZyoHyE26X02nac+Y+H5hxhvbHVXWU8/UugIgMAWYDQ53nPCkitvClOafmZuW1dQVMGtCD3glRbpdjAkxwkPDbW0YREhzEtxduoL6x2e2SOkWb4a6qK4GKdv68mcBCVa1T1f20LJI9rgP1mQDw+d4jFB6tsQupxjWp8ZE8esMINhdW8dj7u9wup1N0pM/9ARHZ7HTbdHfa0oCCVscUOm3GnNWruQXERYZy5dBkt0sxAWzGsGRuG9+HP6/cxyd7ytwup8MuNNyfAvoDo4Bi4LHz/QEiMk9EckUkt6zM999Ic2GqTjbw3rbDzBqVSkSo9eAZd/3oa0PI6hXNdxdt8vn+9wsKd1UtUdUmVW0GnuGLrpcioPW/rdOdtjP9jKdVNVtVsxMTbehboHprYxH1jc3cPNa6ZIz7IsOCefK2i2lWZc4zq3064C8o3EUkpdXD64FTI2mWArNFJFxEMoEsYG3HSjT+bFFOAcPSYhmaGud2KcYAkJUUw8v3jqeusdmnA749QyFfAVYBg0SkUETuAX4lIltEZDNwGfBdAFXdBrwKbAfeA+5X1cCYGd+ct61FVWwvPsYtdiHVeJmLUmJ9PuDFG+7Kys7O1tzcXLfLMF3sx29t5dXcAtb+38uJiwx1uxxjvmRH8TFue3YN4SFBvPIvE8jo2c3tkv6JiKxT1ewz7bM7VI0rahuaeGtjEVcNS7ZgN17Ll8/gLdyNK97bepjq2ka7kGq8nq8GvIW7ccWinAL6JEQxIbOH26UY0yZfDHgLd9Pl8o+cYNW+I9ycnU6QTRJmfISvBbyFu+lyr+UWEiRwwxhbbcn4Fl8KeAt306WampXX1xUyZWAiKXGRbpdjzHnzlYC3cDddauXuMg4fq7Wx7can+ULAW7ibLrUop4Ae3cKYflGS26UY0yHeHvAW7qbLlB+v48MdJVw/Oo2wEPvoGd/XOuBnP72awqMn3S7pH+wvzHSZN9cX0dis3GJj240fORXwJ+oa+dZL66lt8I4ZVyzcTZdQVRblFjC6TzxZSTFul2NMp7ooJZbHbh7JlqIqfv72drfLASzcTRdZf7CSvNLjdiHV+K2vDk3mW1P788rag7yWW9D2EzzMwt10iVdzCogKC+aakalul2KMx3z/ioFM7NeDH721lW2HqlytxcLdeNyJukbe2XyIrw1PITo8xO1yjPGYkOAgfn/raOKjQvnWS+upqmlwrRYLd+Nxf91czIn6JruQagJCz+hwnrztYg5V1vD9VzfS3OzOtOoW7sbjFuUW0D+xG2P6dm/7YGP8wJi+Cfzoaxfx4Y5Snvp4rys1WLgbj9pTUs26/KPMHtsHEZskzASOuZdkcN3IVB57fxef5ZV3+etbuBuPWpRTQGiwcP3FaW6XYkyXEhH+++vD6Z8Yzb+9soHiqpouff32rKH6vIiUisjWVm0JIvKBiOxxvnd32kVEnhCRPBHZLCIXe7J4493qGptYvKGIK4Yk0TM63O1yjOly3cJDeOr2MdQ1NHHfy+upb2zustduz5n7fGDGaW0PA8tUNQtY5jwGuArIcr7mAU91TpnGF324vZSKE/XcMraP26UY45oBvaL59U0j2XCwkv/6a9fd4NRmuKvqSqDitOaZwAJnewEwq1X7i9piNRAvIimdVKvxMQtzDpIWH8nkAT3dLsUYV109PIV7J2fy4qp83tpQ1CWveaF97kmqWuxsHwZOTfGXBrS+NavQafsSEZknIrkikltWVnaBZRhvVVBxkk/zyrkpO51gW23JGB66ajDjMhJ4ZPEWdh2u9vjrdfiCqqoqcN4DOVX1aVXNVtXsxMTEjpZhvMyp269vsukGjAEgNDiIP9w6muiIEP71pXVU13r2BqcLDfeSU90tzvdSp70IaP3XnO60ecTBIyeZ92IuR0/Ue+olzAVoalZezS1kSlYiafG22pIxp/SKjeAPc0ZzsOIkP3htMy3nxp5xoeG+FJjrbM8FlrRq/4YzamYCUNWq+6bT7S07zke7y7jhT59TUOE98ygHulOrLc22O1KN+ZLx/Xrw8IzBvLftMM98ss9jr9OeoZCvAKuAQSJSKCL3AL8ErhCRPcDlzmOAd4F9QB7wDHCfR6p2XDa4Fy/fO54jx+u5/snP2Vrk7kQ9psXCnIO22pIx53DvpZlcNSyZR9/bxep9RzzyGu0ZLTNHVVNUNVRV01X1OVU9oqrTVTVLVS9X1QrnWFXV+1W1v6oOV9Vcj1TdytiMBN741kTCQ4K45c+rWLnbLs66qbS6lmU7SrlhTLqttmTMWYgIv7pxBBk9oliXf9Qjr+EXf30DesWw+L5L6J0Qxd3zc3hjXaHbJQWsxc5qSzfbhVRjzikmIpS3/20y9182wCM/3y/CHSApNoJX/3Ui4/sl8P3XNvHHFXkevVhhvkxVWZRTwNiM7gzoFe12OcZ4vagwz02B7TfhDhAbEcoLd45j5qhUfv33Xfx4yVaaXJpuMxCt3V/B/vITdkeqMV7A71ZOCAsJ4vGbR5EcG8GfV+6j9FgdT8wZTURosNul+b1FOQXEhIdw9fBkt0sxJuD51Zn7KUFBwiNXX8RPrx3CBztKuO3ZNTYW3sOqahr465ZirhuV6tF/ahpj2scvw/2UuyZl8uStF7OlqMrGwnvY0o1F1DU2M9u6ZIzxCn4d7gBXDU/hpXvGU15dx9efsrHwnrIwp4AhKbEMS4t1uxRjDAEQ7gDjMhN441uXEBok3PLnVXyyx8bCd6atRVVsO3SM2eN622pLxniJgAh3gKykGBbfN4neCVHc9UIO8z/bb0MlO8nCnIOEhwQxc6SttmSMtwiYcAdIjmsZCz9lYCI/e3s7d8/Pofx4ndtl+bSa+iaWbDjE1cNTiIsKdbscY4wjoMIdWsbCPzc3m59fN5TP9h5hxm9XsmJXadtPNGf07pZiqusaucUmCTPGqwRcuEPLvA5zL8ng7Qcm06NbOHe9kMPPlm6jtqHJ7dJ8zqKcAjJ6RDE+M8HtUowxrQRkuJ8yKDmGJQ9M4s5LMpj/+QFm/fGzLlkhxV/sLTvO2gMV3DK2j11INcbLBHS4A0SEBvOz64bywl1jKT9ex3V/+JQFnx+wi63t8GpOASFBwg1j7EKqMd4m4MP9lMsG9eJvD05hYv8e/HTpNu5dkGsXW8+hvrGZN9YXMv2iXvSKiXC7HGPMaSzcW0mMCeeFO8fys2uH8EleOTN++wkf2/zwZ7R8Zwnlx+vtjlRjvJSF+2lEhDsnZbL0gUkkdAtl7vNr+Y+3t1PXaBdbW1uYU0BybARTBtri5sZ4ow6Fu4gcEJEtIrJRRHKdtgQR+UBE9jjfu3dOqV1rcHIsSx+YzNyJfXn+s/3M/MNn7C077nZZXqGosoaPd5dxc3Y6wUF2IdUYb9QZZ+6XqeooVc12Hj8MLFPVLGCZ89gnRYQG8/OZw3j+zmzKquuY8/Rqm3wMeC23AICbbLUlY7yWJ7plZgILnO0FwCwPvEaXmjY4iVfmTaC2oYm5z6+lIoCnD25qVl7LLWTygJ70TohyuxxjzFl0NNwVeF9E1onIPKctSVWLne3DQNKZnigi80QkV0Ryy8q8/6LlwKQYnr9zLEWVNdw9P4eT9Y1ul+SKT/PKKaqssTtSjfFyHQ33yap6MXAVcL+ITGm9U1sGi59xwLiqPq2q2aqanZjoGxflsjMSeGLOaDYXVnL/y+tpaGp2u6QuVdvQxB+W76F7VChXDDnj/7ONMV6iQ+GuqkXO91LgTWAcUCIiKQDOd7+auOXKocn816zhrNhVxiOLtwTMzU6NTc18+5UN5Bw4yk+uHUJ4iC1baIw3u+BwF5FuIhJzahv4KrAVWArMdQ6bCyzpaJHe5tbxffjO5Vm8vq6Q/3l/l9vleFxzs/Lw4i28v72En1wzhOtHp7tdkjGmDR1Z7DIJeNOZUyQE+IuqviciOcCrInIPkA/c3PEyvc+D07MoOVbHH1fsJTE6nDsnZbpdkkeoKr94dwevryvkwelZ3D3ZP39PY/zNBYe7qu4DRp6h/QgwvSNF+QIR4T9nDqX8eB0/f2c7iTERfG1Eittldbo/LM/juU/3c+clGXzn8iy3yzHGtJPdodoBIcFB/H7OaMb06c53F23k873lbpfUqV5cdYDHPtjN10en8ZNrhtjMj8b4EAv3DooIDebZudn07RHFN19cx/ZDx9wuqVO8taGInyzZxuUXJfHojSMIsjtRjfEpFu6dID4qjAV3jyM6IoS5L6z1+btYl+0o4fuvbWJCvwT+cOtoQoPtY2KMr7G/2k6SGh/JgrvHUefjd7Gu3neE+15ez9DUWJ6dO5aIUBvyaIwvsnDvRAOTYnjOuYv1Lh+8i3VrURX3LsglvXsk8+8aR3R4RwZTGWPcZOHeycY6d7Fu8bG7WPNKj/ON59cSFxnKS/eOJ6FbmNslGWM6wMLdA64cmsx/zhrGil1lfHfRRo7XefcZfFFlDd94bg1BAi/dO56UuEi3SzLGdJD9u9tDbhvfl6qaBn79911sLKjkVzeM4JIBPd0u60vKj9dxx7NrqK5rZOG8CWT27OZ2ScaYTmBn7h5039QBvPbNiYQECbc+u4Yfv7WVE150Fn+stoG5z6/lUFUNz985lqGpcW6XZIzpJBbuHpadkcDfHpzC3ZMyeWlNPjN+t5LV+464WlNjUzPvbT3MnKdXs+twNU/dPoaxGQmu1mSM6VziDbMaZmdna25urttleNza/RX84PVN5B85ydyJfXnoqsFEhXVdz1hZdR2Lcg7ylzUHOVRVS2pcBD+9bihXDk3ushqMMZ1HRNa1WgXvn/dZuHetk/WN/Oq9Xcz//AB9EqL49Y0jGN+vh8deT1VZf/AoL67K590txTQ0KZMH9OSOiX2ZPrgXIXaDkjE+y8LdC63ed4Qfvr6ZgqMnufOSDH545WAiwzrvhqGa+iaWbCzixVX5bC8+Rkx4CDeMSeeOiX3pnxjdaa9jjHGPhbuXOlnfyKN/28mCVflk9Iji1zeN7HDf94HyE/zv6nxeyy3gWG0jg5NjuGNiX2aNSqOb3ZRkjF+xcPdyq/Ye4YdvbKLwaA13T8rk/3x10JfO4publbrGZuoam6hrbKa24Z+/lx6rY1FuASt3lxESJFw5LJm5EzMYm9HdZnM0xk9ZuPuAE3WNPPreTl5clU9CtzAiQ4O/CPOGZurbcadrr5hwbh3fh1vH9aFXbEQXVG2McdO5wt3+ne4luoWH8B8zhzFjaDKvrSskSITw0CDCQ4KICA0mPCSI8JBgIkJbvoeHBBEeGkRESDDhoUFEhYUwIj3OZnA0xgAeDHcRmQH8DggGnlXVX3rqtfzJJQN6euWdrMYY3+KR0zwRCQb+CFwFDAHmiMgQT7yWMcaYL/PUv+HHAXmquk9V64GFwEwPvZYxxpjTeCrc04CCVo8LnbZ/EJF5IpIrIrllZWUeKsMYYwKTa1ffVPVpVc1W1ezExES3yjDGGL/kqXAvAnq3epzutBljjOkCngr3HCBLRDJFJAyYDSz10GsZY4w5jUeGQqpqo4g8APydlqGQz6vqNk+8ljHGmC/z2Dh3VX0XeNdTP98YY8zZecX0AyJSBuRf4NN7AuWdWI4vs/eihb0PLex9aOHP70NfVT3jiBSvCPeOEJHcs82tEGjsvWhh70MLex9aBOr7YBORGGOMH7JwN8YYP+QP4f602wV4EXsvWtj70MLehxYB+T74fJ+7McaYL/OHM3djjDGn8elwF5EZIrJLRPJE5GG363GLiBwQkS0islFEAmpJKxF5XkRKRWRrq7YEEflARPY437u7WWNXOMv78DMRKXI+FxtF5Go3a+wKItJbRFaIyHYR2SYiDzrtAfeZ8Nlwtznjv+QyVR0VgEO+5gMzTmt7GFimqlnAMuexv5vPl98HgMedz8Uo58ZCf9cIfF9VhwATgPudXAi4z4TPhjs2Z7wBVHUlUHFa80xggbO9AJjVlTW54SzvQ8BR1WJVXe9sVwM7aJluPOA+E74c7m3OGR9AFHhfRNaJyDy3i/ECSapa7GwfBpLcLMZlD4jIZqfbxu+7IloTkQxgNLCGAPxM+HK4my9MVtWLaemiul9EprhdkLfQluFggTok7CmgPzAKKAYec7WaLiQi0cAbwHdU9VjrfYHymfDlcLc54x2qWuR8LwXepKXLKpCViEgKgPO91OV6XKGqJarapKrNwDMEyOdCREJpCfaXVXWx0xxwnwlfDnebMx4QkW4iEnNqG/gqsPXcz/J7S4G5zvZcYImLtbjmVJg5ricAPhciIsBzwA5V/U2rXQH3mfDpm5icoV2/5Ys543/hbkVdT0T60XK2Di1TOP8lkN4HEXkFmErLzH8lwE+Bt4BXgT60zDZ6s6r69cXGs7wPU2npklHgAPDNVv3OfklEJgOfAFuAZqf532npdw+sz4Qvh7sxxpgz8+VuGWOMMWdh4W6MMX7Iwt0YY/yQhbsxxvghC3djjPFDFu4mIIlIRusZFI3xNxbuxnQSEQlxuwZjTrFwN4EsWESeceb9fl9EIkVklIisdibbevPUZFsi8pGIZDvbPUXkgLN9p4gsFZHltEwla4xXsHA3gSwL+KOqDgUqgRuAF4GHVHUELXc5/rQdP+di4EZV/YqnCjXmfFm4m0C2X1U3OtvraJlBMV5VP3baFgDtmWHzA3+/ld34Hgt3E8jqWm03AfHnOLaRL/5eIk7bd6ITazKmU1i4G/OFKuCoiFzqPL4DOHUWfwAY42zf2MV1GXPe7Oq+Mf9sLvAnEYkC9gF3Oe3/A7zqrHT1V7eKM6a9bFZIY4zxQ9YtY4wxfsjC3Rhj/JCFuzHG+CELd2OM8UMW7sYY44cs3I0xxg9ZuBtjjB+ycDfGGD/0/wFJDcpgyl8ebgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.2 - \"workingday\"=0 escriba su código y hallazgos \n",
    "bikes_1 = bikes[bikes[\"workingday\"] == 0]\n",
    "bikes_1.groupby(by='hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwB0lEQVR4nO3dd3xc9Znv8c8zoz7qxeq2xg03sGzLpoQWqkkCTjFtU0gCYe8uuYGQ3SSbu3ez9+7uTbIhS8guy4a2QBIgBEggCb1XgwvG2JJtZEm21ayukUZd87t/6IyRjWS1mTlTnvfr5ZfOnBnNPB6Pvj76nd95fmKMQSmlVHRx2F2AUkqpwNNwV0qpKKThrpRSUUjDXSmlopCGu1JKRaE4uwsAyM3NNWVlZXaXoZRSEWX79u1txpi8ie4Li3AvKytj27ZtdpehlFIRRUQOTnafDssopVQU0nBXSqkopOGulFJRSMNdKaWikIa7UkpFIQ13pZSKQhruSikVhTTclVKz1tDVz++2HUZbh4cfDXel1Kw98FYdf/voLn7w+w/w+TTgw4mGu1Jq1mravMQ7hYfePcx3fvc+I6M+u0tSlrBoP6CUiky1bV7OWzaPk4szuOW5/QwMj3LbVWtIiNPjRrvpv4BSalZGfYaD7V7cual887wl/P2nl/P07mb+6tfbGRgetbu8mKfhrpSalYbOfoZHDQtzXQBcd9ZC/vmzq3hxbwvX3b+NvqERmyuMbRruSqlZqWnrBcCd5zq670unLeCWy1fz1oE2vnrvVnoGhu0qL+ZpuCulZqW2zQuAO9d1zP7N60r4xdVr2HGoky/d8y5dfUN2lBfzNNyVUrNS2+YlLSmOHFfCx+77zClF/OcX11LV6OHqu96hvXfQhgpj27TCXUTqROQDEdkpItusfdki8ryIfGh9zbL2i4j8QkSqRWSXiKwN5l9AKWWP2jYvC3NdiMiE91+0soC7rqmgprWXK+/cwhHPQIgrjG0zOXL/pDGm3BhTYd3+PvCiMWYJ8KJ1G+ASYIn153rgjkAVq5QKHzWt3o8NyRzvnKV53P/1DTR29XPFL9+mvrMvRNWpuQzLbALut7bvBz47bv8DZswWIFNECufwOkqpMDMwPEpjdz/u3NQpH3vawhx+fd2pdHiHuPKXW6izxupVcE033A3wnIhsF5HrrX35xpgma7sZyLe2i4HD47633tp3DBG5XkS2ici21tbWWZSulLLLwfY+jDl2psyJrJ2fxUPfOI2+oRGu+OXbVLf0BLlCNd1wP9MYs5axIZcbROTs8Xeasa5BM2osYYy50xhTYYypyMubcPFupVSYqrWmQS6cYlhmvFXFGTx8/en4DFz5yy206Bh8UE0r3I0xDdbXFuD3wAbgiH+4xfraYj28ASgd9+0l1j6lVJSosYZWymYQ7gAnFaRx71craPcO8dLelqm/Qc3alOEuIi4RSfNvAxcBu4EngWush10DPGFtPwl8xZo1cxrQPW74RikVBWpbvcxLSyQ1cebtqU4uziA3NYF36zqCUJnym86/TD7we2u6UxzwoDHmGRHZCjwiItcCB4ErrMc/BXwKqAb6gK8FvGqllK1q26aeKTMZEWF9WTbv1mq4B9OU4W6MqQFWT7C/HTh/gv0GuCEg1SmlwlJtm5eLVuZP/cBJrC/L5undzTR29VOUmRzAypSfXqGqlJqR7r5h2r1Dsz5yB9jgzgZgqw7NBI2Guwq6B985xF//ZrvdZagAqW3395SZeo77ZJYXppOaGKdDM0Gki3WooPvzB428daCdgeFRkuKddpej5sg/DXIuR+5Oh7BuQZaGexDpkbsKKmMMVU09GAOHO/TS82hQ2+rFITA/O2VOz7PBnc2HLb10eLVrZDBouKugOuIZPPrDW6OXnUeFmjYvJVkpc15KT8fdg0vDXQVVVZPn6HathntUmMs0yPFOKckgIc7BVh2aCQoNdxVUlVa4pyXGUduq4R7pjDEBC/fEOCflpZl6MVOQaLiroKps8lCancyywjQ9co8CrT2D9A2NsnCaDcOmcqo7mz2NHnoHdb3VQNNwV0FV1ehhRWE6ZTmuo1PoVOSqmWRpvdlaX5bNqM+w42BnQJ5PfUTDXQVN39AIte1elhem485z0dozqAsmR7jJ1k2drbULsnA6RE+qBoGGuwqavc1jUyBXFKYfbQ1b16bTISNZbZuXhDgHRRmBaRmQmhjHyqJ0ne8eBBruKmj8M2WWF6YfvZqxxroARkWmmlYv7hwXDsfE66bOxoaybN473MXgyGjAnlNpuKsgqmz0kJYUR0lWMgtyUhDR6ZCRrratN2BDMn7r3dkMjfj4oL47oM8b6zTcVdBUNXlYXpiOiJAU76QoI1nXz4xgI6M+DnX0TXtpvelaXzZ2MdM7OjQTUBruKih8PsPe5h5WFKYf3efOdemRewRr6OpneNQE/Mg925XAknmpelI1wDTcVVAc7Oijb2j0Y+Fe0+ZlrOW/ijT+aZAzWTd1uta7s9le18moTz8bgaLhroLCfzJ1RdGx4d4zMEK7NoqKSP4rjAN95A5jFzP1DI4c065CzY2GuwqKykYPToeweN5HPb/9Y7U6NBOZatu8pCfFke1KCPhz+8fddUpk4Gi4q6CoavKwKM91TP92/6/zGu6RqbbNizsvFWs95YAqykymJCtZx90DSMNdBUVlk+eY8XaA4sxk4hyi4R6hatu8QRlv99tgLZqt52QCQ8NdBVynd4im7gGWHxfucU4H83NStDtkBBoYHqWhqz8o4+1+G9zZtHuHtO9/gGi4q4Cb6GSq30KdDhmR6tqDdzLVb71bx90DScNdBVzluLYDx3PnjnWH9OmUt4gSzJkyfgtzXeSmJujiHQGi4a4CrrLJw7y0RHJTEz92nzs3laERH43d/TZUpmYr0K1+JyIirC/L1itVA0TDXQVcVVPPhEftAGW5Y4sqa3fIyFLb5iU/PRFXYlxQX2eDO5uGrn4auvQ//7nScFcBNTTio7qlZ8LxdoCFVnfIWu0OGVFq27yU5QTvqN3PP99dh2bmTsNdBVR1Sy/Do2bSI/f89ESS4506IyLC1LZ5A7a03oksL0wnLTFO11UNAA13FVD+k6nHz3H3ExFtIBZhuvqG6PAOBXW83c/pENaVZemRewBouKuAqmrykBTvOGEQuPM03CPJR0vrpU7xyMDY4M7mw5ZeOrQH0ZxMO9xFxCki74nIn6zbbhF5R0SqReS3IpJg7U+0bldb95cFqXYVhiobPZxUkI7zBCv1uHNc1Hf2MzTiC2FlarYCvW7qVDb4x911aGZOZnLkfiNQNe72T4BbjTGLgU7gWmv/tUCntf9W63EqBhhjqGr2sKIw7YSPc+e6GPUZDnfqjJlIUNvmxSEwPzslJK93ckkGiXEOvZhpjqYV7iJSAnwauNu6LcB5wKPWQ+4HPmttb7JuY91/vgSj05AKO03dA3T1DU863u53tDuktiGICLVtXkqzU0iIC80obmKck/LSTD1yn6Pp/mv9HPgu4P89OgfoMsaMWLfrgWJruxg4DGDd3209/hgicr2IbBORba2trbOrXoWVqhNcmTqedoeMLLVt3pANyfhtcGezu6Gb3sGRqR+sJjRluIvIZ4AWY8z2QL6wMeZOY0yFMaYiLy8vkE+tbFLZOBbuy6YI98yUBLJS4nU6ZAQwxtgW7j4DOw52hvR1o8l0jtw/AVwmInXAw4wNx9wGZIqI/3K1EqDB2m4ASgGs+zOA9gDWrMJUVbOHBTkppE7jKsayXJculh0BWnoG6RsaDWqr34msnZ+F0yE67j4HU4a7MebvjDElxpgy4CrgJWPMF4GXgc3Ww64BnrC2n7RuY93/ktEGzTGhsvHjPdwno3PdI0NNa2inQfq5EuNYVZSuFzPNwVzOkHwPuFlEqhkbU7/H2n8PkGPtvxn4/txKVJGgd3CEgx19U463+y3MddHsGcCrY6ph7eg0yBBcnXq89WXZ7DzcxeDIaMhfOxrMKNyNMa8YYz5jbdcYYzYYYxYbYy43xgxa+wes24ut+2uCUbgKL/uaPRgz9clUP/+RoL9PuApPtW29JMY5KExPCvlrb3BnMzTiY1d9d8hfOxroFaoqICqbeoCJF+iYiFtnzEQE/8lUxwkuSgsWXTR7bjTcVUBUNnpIT4qjKGN6R3gftf7VcA9nNTbMlPHLciWwND9Vw32WNNxVQFQ1eVhRlM50r1dLSYijID1Jp0OGsZFRH4fa+2wLdxg7et9+sJNRXblrxjTc1ZyN+gx7mz3THm/30xkz4a2+s58Rn7E13De4s+kdHDl6gZyaPg13NWd17V4Ghn3Tngbpp90hw5v/3yYUfdwns0EXzZ41DXc1Z/4rU2d65L4w10VX3zCd2to1LNWEuNXvRAozkinNTtZwnwUNdzVnVU0e4hzCkvyZhcDRGTM6HTIs1bb1kpEcT1ZKvK11rC/LZmtdB3ot5MxouKs5q2rysHheKolxzhl9X1mudocMZ/5pkHY3dT3VnU27d4gD+jmZEQ13NWeVTdNvOzBeaVYKTofouHuYqm31hrynzETW6+Ids6LhruakvXeQI57BGY+3AyTEOSjNStZwD0P9Q6M0dg8c/e3KTu5cF7mpCTruPkMa7mpOqmZ4Zerx3LkunesehvxtIeycBuknImxwZ2u4z5CGu5qT6S7QMRl3bip1bV49WRZmQr1u6lTWl2XT0NVPQ1e/3aVEDA13NSeVTR4K0pPIdiXM6vvduSn0D49yxDMY4MrUXIRbuH80312XhpguDXc1J1VNHpZPsSD2ifjnUNe09QaqJBUANa1e8tMTcU1j4ZVQWFaQTo4rgRcqW+wuJWJouKtZGxwZpbqld9bj7TBusWwddw8rtW29YXPUDuB0CJ85pZAXqo7QMzBsdzkRQcNdzdqHR3oZ8ZlZj7cDFKYnkRjn0LnuYWZsjrt9V6ZO5LLyYgZHfDy354jdpUQEDXc1a5XWydTZzHH3czhEG4iFma6+ITr7hsNijvt4a+dnUpKVzBPvN9pdSkTQcFezVtXkITneyYKcuYVAWY5LWxCEkXA7meonImwqL+LN6jZae/QE/FQ03NWsVTZ6OKkgDeccV+lx57k41N7HyKgvQJWpubBz3dSpbCovZtRneOqDJrtLCXsa7mpWjDFHF+iYK3euixGfob5T5zCHg9o2L06HUJqVYncpH7M0P41lBWk8sbPB7lLCnoa7mpWGrn48AyNzOpnqt1DXUw0rNW1eSrOSSYgLz3jYVF7MjkNdHGrvs7uUsBae/3oq7B1tOxCAcPeP7WobgvBQ22rfuqnTcenqQgD+uEtPrJ6IhrualcpGDyKwrGD2FzD5ZbsSSEuK08Wyw4AxJiynQY5XkpVCxYIs/vBeg7atOAENdzUrVU0eynJcAbmCUURYqNMhw8IRzyD9w6NheTJ1vE3lRXzY0sve5h67SwlbGu5qVirn2HbgeDrXPTz420CE2xz3433q5EKcDuGJnTo0MxkNdzVjPQPDHOroC8h4u587N5WGrn4GhkcD9pxq5sJ1jvvxclITOWtJLn98vxGfT4dmJqLhrmbM/6twIGbK+PmHAer0YiZb1bZ6SYp3UJCeZHcpU9pUXkRDVz/bD3XaXUpY0nBXM+bv4R6IOe5+/mEAPalqr9o2L2U5LhxzvDAtFC5cUUBSvIMndWhmQlOGu4gkici7IvK+iOwRkf9j7XeLyDsiUi0ivxWRBGt/onW72rq/LMh/BxVilY0eMlPiA3p0V6bTIcNCbZuXhWF+MtUvNTGOC5bn8+cPmhjWq5s/ZjpH7oPAecaY1UA5sFFETgN+AtxqjFkMdALXWo+/Fui09t9qPU5FkSprQWyRwB3dpSbGkZeWqN0hbTQ86uNQR1/Yj7ePt6m8mA7vEG9Ut9ldStiZMtzNGP9KCvHWHwOcBzxq7b8f+Ky1vcm6jXX/+RLIFFC2Ghn1sbe5J6Dj7X46Y8Ze9Z39jPhMWM9xP945S/PISI7XoZkJTGvMXUScIrITaAGeBw4AXcaYEesh9UCxtV0MHAaw7u8GcgJYs7JRXbuXwRFfQGfK+Olcd3vVWtMg3bnh11NmMglxDj51cgHP7mmmf0hnWo03rXA3xowaY8qBEmADsGyuLywi14vINhHZ1traOtenUyGyp3FuC2KfiDvXRbt3iO5+XWnHDjWt/mmQkXPkDnDZ6mL6hkZ5oUoX8RhvRrNljDFdwMvA6UCmiPgvTywB/G3aGoBSAOv+DOBjq9oaY+40xlQYYyry8vJmV70KuaqmHuKdwuJ5gQ+AMp0xY6vaNi8ZyfFkpcTbXcqMbHBnU5CepBc0HWc6s2XyRCTT2k4GLgSqGAv5zdbDrgGesLaftG5j3f+S0QYQUaOyycPieWlB6Rio3SHt9UFDN4vyXAE9UR4KTodw6epCXt3fQlffkN3lhI3p/IQWAi+LyC5gK/C8MeZPwPeAm0WkmrEx9Xusx98D5Fj7bwa+H/iylV2qAtx2YLz5OSmI6HRIO1S39LKrvptLVhXaXcqsbCovZnjU8PTuZrtLCRtTdn0yxuwC1kywv4ax8ffj9w8AlwekOhVWWnoGaO0ZDMrJVIDEOCclWcl65G6Dx3bU43QIm9YU2V3KrKwsSmdhnosndjZw9Yb5dpcTFvQKVTVtR3u4B/DK1OO5c1N1zD3ERn2Gx3fUc+7SPOalhX/bgYmICJtWF/NObQdN3bqiF2i4qxk42nYgSEfuAO6cFGrbvNqnO4TeqG7jiGeQL6wrsbuUObmsvAhj4E/v6/qqoOGuZqCy0UNxZjKZKQlBew13rovewRFae3V1+1B5dHs9GcnxnL98nt2lzIk718UpJRk88b6urwoa7moGxnq4B++oHcCdNzbFUtsQhEZ3/zDP7WlmU3kRiXFOu8uZs8tWF7G7wcOB1t6pHxzlNNzVtAwMj1LT2suKIM2U8dPpkKH1511NDI742BzhQzJ+l64uQgRtR4CGu5qmfc09+ExwT6YCFGUmk+B0UKt93UPi0e2HWTIvlZOLM+wuJSDy05M4fWEOT77fGPPnbTTc1bRUHj2ZGtwQcDqE+TkpOiwTAgdae9lxqIvN60oi7sKlE9lUXkRtm5cPGrrtLsVWGu5qWiobPaQlxlGSlRz019LukKHx+I56HAKfW1M89YMjyMaVhSQ4HTHfjkDDXU1LZZOHZYVpIVmhZ2Gui4PtfYzq2phBMza3vYFzluYxLwKW1JuJjJR4zj0pjz++3xjTnyENdzUln8+w11qgIxTcuS6GRn00dunFKMHy1oE2mroHIn5u+2Q2lRfT0jPIOzUf61kYMzTc1ZQOdfThHRoN+slUP7cuuRd0j22vJz1pbJm6aHT+8nm4EpwxPTSj4a6mFKqTqX5ubf0bVJ6BYZ7Z08xl5UUkxUf+3PaJJMU7uXhVAU/tbmJwJDYX8dBwV1OqbPTgdAhL8kOziENeWiKuBKeeVA2Sp3Y1MTDsY/O6UrtLCapN5cX0DIzwyr7YXAxIw11NqarJw6I8V8iO8kQEd55Lh2WC5NHt9Syel8rqkuiY2z6ZTyzKITc1gd9tO2x3KbbQcFdTqgzhyVQ/d27q0TU9VeDUtXnZdrCTL6yNrrntE4lzOvjyaWW8UNXC9oOddpcTchru6oQ6vEM0dQ+E7GSqnzvXRUNnf8yOlwbLY1E6t30y153lJjc1kR89VRVzV6xquKsTqgrxyVS/JfNS8Zmx8X4VGD6f4bHt9Zy1JI+CjOia2z4ZV2Ic375wCdsOdvJ8ZWwtoK3hrk7IH+7BWlpvMmcvySPOITy7J7Z+IIPp7Zp2GrsHoqZJ2HRdWVHKwjwXP3lmLyOjPrvLCRkNd3VClY0e8tMTyUlNDOnrZqTEc/qiHJ7Z3RRzv04Hy2Pb60lLiuPCFdE5t30ycU4H3714GQdavTyyrd7uckJGw12dkB0nU/02riqgrr2PfUd6bHn9aNIzMMxTu5u4dHX0zm0/kYtX5rNuQRa3vrCfvqERu8sJCQ13NamB4VGqW3pDfjLV76IVBYjA0x/oivZz9fQHzdbc9tgakvETEX7wqWW09gxyz+u1dpcTEhrualLVLb2M+EzQV1+aTF5aIusXZPPMbg33uXp0ez0L81ysKc20uxTbrFuQzUUr8vmvVw/QFgPLOGq4q0lVhmBB7KlsXFXAviM91OiyabN2sN3Lu3UdMTG3fSrf3biMgREf//7ih3aXEnQa7mpSlY0eUhKcLMhx2VbDxlUFADyzR4/eZ+uxHQ2IwOfXxsbc9hNZPC+VK9eX8pt3DkV97yINdzWpyiYPywrScIagh/tkijKTWV2SoUMzs+Sf237m4lwKM4K/0EokuOn8JcQ7Hfz0uX12lxJUGu5qQsYYqpo8tp1MHW/jqkJ21XfToP3dZ+yd2g4auvpj9kTqROalJ/GNs9z8eVcTOw932V1O0Gi4qwnVd/bTMzBi28nU8Y4OzejR+4w9ur2etMQ4Ll5ZYHcpYeX6cxaR40qI6rYEGu5qQuFwMtXPnetiWUEaz+xusruUiOIdHOHp3U18ZnVhTM5tP5HUxDhuvGAJ79R28PK+FrvLCQoNdzWhykYPDoFlBfaHO4wdvW872ElLz4DdpUSMpz5oom9oVIdkJnH1hvmU5aTw46f3RuVaq1OGu4iUisjLIlIpIntE5EZrf7aIPC8iH1pfs6z9IiK/EJFqEdklImuD/ZdQgVfZ5MGd6yI5ITyO+C5ZVYgx8Jz2mpm2x3bU4851sXZ+lt2lhKV4p4PvblzG/iO9PLY9+toSTOfIfQT4jjFmBXAacIOIrAC+D7xojFkCvGjdBrgEWGL9uR64I+BVq6CravKExXi739L8VNy5Lh13n6bDHX1sqelg8zqd234il6wqoLw0k397fj/9Q9HVXnrKcDfGNBljdljbPUAVUAxsAu63HnY/8FlrexPwgBmzBcgUkcJAF66Cp7t/mPrO/rCYKeMnImxcVcDbNe109Q3ZXQ6jPkN9Zx/d/cP4wvBX+sd21CMx1Ld9tkSEv7tkGc2eAe59M7raEsTN5MEiUgasAd4B8o0x/jNczYC/1VwxMH5dq3pr3zFnw0TkesaO7Jk/f/5M61ZBVBVGJ1PHu2RVAXe8coDnK49weYV9638OjozypbvfYWvd2Oo+ImMn6NKT4klPjic9Kc76Gk968rH7izKTOX1hDo4gXTtgjOHFqhZ+veUQn1iUS1Gmzm2fyqkLc7hg+Tz+65UDXL1hPtmuBLtLCohph7uIpAKPATcZYzzjf9UzxhgRmdHhizHmTuBOgIqKivA79Ilh/gUywunIHeDk4gyKM5N5ZnezbeFujOHvHv+ArXWd3Hj+EtKS4vD0D+MZGMEzMIynf+zr4Y4+egZG8PQP0zN4bBfCxfNS+etzF3HZ6iLinIGb0/BmdRs/fXYfOw93sSAnhb+9+KSAPXe0+97GZVz889f4j5eq+YdLV9hdTkBMK9xFJJ6xYP+NMeZxa/cRESk0xjRZwy7++UQNwPifvBJrn4oQVU0eclMTmJcWXqv1iAgXryzg11sO0js4QmrijH7xDIg7X6vh8R0N3HTBEm66YOm0vmfUZ+i1wn/HoU7ueOUANz/yPre+sJ+/PHsRm9eVzGmq4vaDndzy7D7ermmnMCOJH33+ZDavKyE+gP9xRLsl+Wlcvq6UX22p46tnlDE/J8XukuZsOrNlBLgHqDLG/Nu4u54ErrG2rwGeGLf/K9asmdOA7nHDNyoCVIbZydTxLjm5gKFRHy/tDf3c5BerjvDjZ/by6VMKufH8JdP+PqdDyEiJpzQ7hU3lxTx941nc/ZUKclyJ/P0fdnP2v77MXa/V4B2cWZ/xPY3dXHvfVr5wx1t82NLDP3xmBS//zblcvWG+BvssfPvCpTgdwi1R0pZgOoc+nwC+DHwgIjutfT8Afgw8IiLXAgeBK6z7ngI+BVQDfcDXAlmwCq6hER8fHunla2eW2V3KhNbOzyI3NZFndjdx2eqikL3uvuYevvXQe6wsSueWzavnNANFRLhgRT7nL5/H2wfauf2Vav7lqSpuf6War53h5pozFpCZMvm474HWXv7t+f38eVcT6Ulx/O3FJ/HVM8pw2fCbTDQpyEji2jPd3P7yAb5x1kJOLgntusGBNuWnwRjzBjDZJ/n8CR5vgBvmWJeyyYHWXoZGfWF3MtXP6RAuXpnP4zsaGBgeDcmVlx3eIa57YCspiXHc9ZWKgM39FxHOWJzLGYtz2XGok/98+QC3vrCfO187wJdOX8C1Z7qPGRo73NHHbS9+yOM76kmKd/LNTy7mG2cvJCM5PiD1KPjLcxbx4DuH+JenKnnwutOCduI7FPS/enUM/0yZlWF2MnW8S1YV8pt3DvHq/tag90wZGvHxP369nSOeQX57/WlB66y4dn4Wd19TQVWTh/985QB3vVbDfW/WceX6Ur6wtoTHdtTz0LuHEBG+9gk3f3XuInJDvK5tLEhPiudvLj6J//X73dz1eg1/ec4iu0uaNQ13dYzKRg+JcQ7KbOzhPpVTF2aTkRzPM7ubgxruxhj+4YndvFvbwW1XlbMmBFd6Li9M59+vXsPNFy7lv145wEPvHuKBtw8S5xCuWF/K/zxvsbbuDbK/2DCfNz5s41+f3ce6BVlUlGXbXdKsaLirY/h7uAdyil6gxTsdXLgin2f3NDM04iMhLji1/vebdTy89TA3fHIRm8pDezGQO9fFTzafwo0XLOGFqiOcszTP1kVTYomI8JPNp1D572/wzQff48/fOpOcCPwtKXx/glXIGWOoDJMe7lPZuLKAnoER3jrQFpTnf3V/K//850ouXJHPdy60b754UWYyXzm9TIM9xNKT4rn9L9bS4R3i24+8H5ZXIU9Fw10d1ewZoKtvOGxPpo535pJcXAnOoPSaqW7p5ZsP7mBpfho/v7I8ok+qqdlbVZzB/750Ba/tb+WOVw/YXc6Mabiro/xXpobrHPfxkuKdnLc8n+cqjwS0XWtX3xDX3b+VBKeDu6+p0OmFMe5Lp87n0tVF/Oy5fWypabe7nBnRcFdH+cN9WQSEO4wNzXR4h3i3tiMgzzc86uOGB3fQ0NXPL7+8jpKsyL9KUc2NiPCjz59MWY6Lbz30Hq09g3aXNG0a7uqoyiYPZTkptlzWPxvnnpRHYpwjYCs0/dOfKnmzup3/97mTI3aGhAq81MQ4bv/iWrr7h/n2b3dGzMIeGu7qqEg5mernSozjnKV5PLvnyJxPeP1qy0EeePsg15+90NaOkyo8LS9M5/9ctpI3qtv4j5eq7S5nWjTcFQC9gyMcbO9jeZgsqzddG1cV0OwZYGd916yf463qNv7xyT188qQ8vrdxWeCKU1HlyvWlfH5NMT9/cT9vVgdnllYgabgrAPY2hWeb36mcvzyfeKfMataMz2e4941avn7/VhbmuvjF1Wtw6swYNQkR4Z8/t4pFeanc+PB7tHjCez1fDXcFjA3JQOSFe0ZyPGcsyuWZ3c2MtTWanro2L1fe+Tb/90+VnLEol99cdyppSdqjRZ1YSkIc//nFtXgHR/nWw+8xMuqzu6RJabgrYGymTFZKPAXp4dXDfTo2rirgUEff0f+gTsR/tL7xttfY29zDLZev5p5rKpgXgX9vZY+l+Wn802dXsaWmg9te/NDucial4a6AsYZhK4rSI3Ix5YtW5OMQphyaqWvzctWdW44erT//7XN0AWk1K5vXlXD5uhL+4+VqXtvfanc5E9JwV4yM+tjb3BNxJ1P9clIT2eDOnjTcxx+tVzV7jh6tF2To0bqavf+7aRVL56Vx02930twdfuPvGu6K2jYvgyO+iBtvH2/jygI+bOmluqX3mP3jj9ZPX5ijR+sqYJITnNz+xbUMDI/yrYfCb/xdw11F7MnU8TauKgQ4ekGTz2f47zePPVq/96vr9WhdBdTiean86PMn825dBz97fr/d5RwjMi5FVEFV2eQhwelgUV6q3aXMWkFGEmvmZ/LMnmY+c0oR3310F+/WdfDJk/L40edP0VBXQbOpvJgtNR3c8coBTl+Yw9lL8+wuCdAjd8XYTJkl+akRv6jyxpUF7G7wHD1a/+nmU/RoXYXEDy9dwdL8VL7zu/dp7w2P/jOR/dOs5swYQ2WjJyLa/E7lUycXkhTvODq2fnlFqY6tq5BIindy21Vr6O4b5nuPfTCjay6CRcM9xrX2DNLuHYro8Xa/0uwUdvzvC/VoXdlieWE637tkGS9UHeHBdw/ZXY6Ge6w7ejI1Co7cYewKQj1aV3b52hllnLUkl3/6U+XHZm6FmoZ7jPOH+/IoOHJXym4Oh/Czy1eTHO/kxoffY2jEvumRGu4xrrLRQ0lWMunaV0WpgJiXnsRPvnAKexo9/Oz5fbbVoeEe4yqbouNkqlLh5KKVBfzFqfO587Ua3rKpPbCGewzrGxqhts0bFSdTlQo3f//p5bhzXdz8yPt09Q2F/PU13GPYvuYejImek6lKhZOUhDh+cdUa2r2D/N3joZ8eqeEew46eTNVwVyooVhVn8DcXncTTu5v53bb6kL62hnsMq2z0kJYUR0lWst2lKBW1vnHWQs5YlMM//nEPtW3ekL3ulOEuIveKSIuI7B63L1tEnheRD62vWdZ+EZFfiEi1iOwSkbXBLF7Njf9kqs4LVyp4HA7hZ1esJt7p4KaH32M4RN0jp3Pkfh+w8bh93wdeNMYsAV60bgNcAiyx/lwP3BGYMlWgjfoM+5p79GSqUiFQmJHMjz9/Mu/Xd3PbC6FZvWnKcDfGvAZ0HLd7E3C/tX0/8Nlx+x8wY7YAmSJSGKBaVQA9X3mEvqFRTnXn2F2KUjHhkpMLuaKihNtfqeadmvagv95sx9zzjTFN1nYzkG9tFwOHxz2u3tr3MSJyvYhsE5Ftra3huUxVNLv79RpKs5O5cEX+1A9WSgXEDy9dyYLsFG5+5H26+4eD+lpzPqFqxub3zHiOjzHmTmNMhTGmIi8vPPofx4odhzrZdrCTr3/CjdOh4+1KhYorMY6fX7WGZs8Af/+H3UGdHjnbcD/iH26xvrZY+xuA0nGPK7H2qTBy9+s1pCfFcUVF6dQPVkoFVHlpJt++YAl/fL+R378XvHicbbg/CVxjbV8DPDFu/1esWTOnAd3jhm9UGDjc0cczu5v54mkLcCXqQlxK2eGvzl3M+rIs/uGJPRxq7wvKa0xnKuRDwNvASSJSLyLXAj8GLhSRD4ELrNsATwE1QDVwF/DXQalazdo9b9TidAhfPaPM7lKUillOh3DrleU4HcKbB4LTe2bKQzdjzNWT3HX+BI81wA1zLUoFR3ffMI9sO8ylq4vIT9fFLJSyU0lWCq/+7blkpiQE5fn1CtUY8uC7h+gbGuW6MxfaXYpSCoIW7KDhHjOGRnzc91YtZy7O1QuXlIoBGu4x4k+7GjniGeS6s9x2l6KUCgEN9xhgjOHO12pYmp/KOUv1mgKlYoGGewx4s7qdvc09XHfmQm0SplSM0HCPAXe9XkNuaiKb1hTZXYpSKkQ03KPc/iM9vLq/la+esYDEOKfd5SilQkTDPcrd/XoNSfEOvnjqArtLUUqFkIZ7FGvpGeAP7zVy+bpSslzBm0+rlAo/Gu5R7FdvH2TY5+PaM3X6o1KxRsM9SvUNjfCrLQe5cHk+Zbkuu8tRSoWYhnuUemx7PV19w3zjbG01oFQs0nCPQqM+wz1v1LK6NJOKBVl2l6OUsoGGexR6oeoIde19fOMst160pFSM0nCPQne/XkNxZjIbVxbYXYpSyiYa7lFm5+EuttZ18vUz3cQ59Z9XqVgV0T/9xhhGRn12lxFW7nq9hrSkOK5cr+ujKhXLIjrc/7Sric/8+xtsqWm3u5SwcLijj6c/aOIvTp1Pqq6PqlRMi+hwT0uKo3dwhKvu3MI3H9xBU3e/3SXZ6t43a3GIro+qlIrwcD/3pHm8cPM53HTBEp6vPMJ5t7zK7S9XMzgyandpIdfdP8wjW8fWRy3MSLa7HKWUzSI63AGS4p3cdMFSXrj5HM5emstPn93HRbe+xkt7j9hdWkg99O4hvEOjutKSUgqIgnD3K81O4ZdfruBX124gziF8/b5tfP2+rdS1ee0uLeiGRnzc92YdZyzKYWVRht3lKKXCQNSEu99ZS/J4+saz+V+fWs67tR1cdOtr/Osze/EOjthdWlC8tr+VTbe/SbNngOu11YBSyiLGGLtroKKiwmzbti3gz9viGeDHT+/l8fcaKEhP4gefXs6lpxRGxVWbuxu6+ckze3n9wzZKs5P57sXLuHS1rrSkVCwRke3GmIoJ74vmcPfbVtfBD5/cw55GD6e6s/nHy1ayvDA9aK8XTPWdffzsuf38YWcDGcnx/M/zlvCl0+brKktKxaCYD3cYa6b18NZD/PTZfXT3D7M4L5Xy0kzK52dSXprJSflpYX1FZ3ffMLe/Us19b9YhAl8/083/OGcRGcnxdpemlLKJhvs4nd4hHnz3ENsPdvLeoU46+4YBSI53cnJJBmtKx8J+zfwsCjKSQlLTiQwMj/LA23X8x0vV9AyO8IW1Jdx84VKKMnW6o1Kx7kThHnOXMWa5Erjhk4uBsfYFhzr62Hm4i/cOdbHzcBf//WYdQ1ZLg4L0pGOO7hfmushJTcTpCP6Yvc9neOL9Bm55dj8NXf2ce1Ie39u4LGKHk5RSoRVz4T6eiLAgx8WCHBebyosBGBwZpbLRw87DXUf/PLOn+ej3OARyUxPJT08iPz2RvLSxr/7b89KSmJeeSI5rdv8JGGN4s7qdHz1dxZ5GD6uK0/nXzafwicW5Aft7K6WiX1DCXUQ2ArcBTuBuY8yPg/E6wZAY52TN/CzWzP9okYsO7xDv13dR39lPi2eAFs8gR3oGaOga4L1DXbR7hz72PE6HkJeaSEqik1GfOeaPzxhG/Nu+sW3/Pv8oWUlWMrddVc6lpxThCMFvCkqp6BLwcBcRJ3A7cCFQD2wVkSeNMZWBfq1QyXYl8MmT5k16/9CIj9beQVo8AxzxDNLSM8ARa7t/aBSnQ4hzCI7jv8rYV+dxfwrSk/jc2mKdAaOUmrVgHLlvAKqNMTUAIvIwsAmI2HCfSkKcg+LMZIr1JKdSKkwEY+5fMXB43O16a98xROR6EdkmIttaW1uDUIZSSsUu2yZ2G2PuNMZUGGMq8vLy7CpDKaWiUjDCvQEYvwxQibVPKaVUiAQj3LcCS0TELSIJwFXAk0F4HaWUUpMI+AlVY8yIiHwTeJaxqZD3GmP2BPp1lFJKTS4o89yNMU8BTwXjuZVSSk0tfDtlKaWUmjUNd6WUikJh0RVSRFqBg7P89lygLYDlRCp9Hz6i78UYfR/GRPP7sMAYM+Fc8rAI97kQkW2TtbyMJfo+fETfizH6PoyJ1fdBh2WUUioKabgrpVQUioZwv9PuAsKEvg8f0fdijL4PY2LyfYj4MXellFIfFw1H7koppY6j4a6UUlEoosNdRDaKyD4RqRaR79tdj11EpE5EPhCRnSKyze56QkVE7hWRFhHZPW5ftog8LyIfWl+zTvQc0WKS9+IfRaTB+lzsFJFP2VljsIlIqYi8LCKVIrJHRG609sfkZyJiw33ccn6XACuAq0Vkhb1V2eqTxpjyGJvPex+w8bh93wdeNMYsAV60bseC+/j4ewFwq/W5KLd6PkWzEeA7xpgVwGnADVYmxORnImLDnXHL+RljhgD/cn4qRhhjXgM6jtu9Cbjf2r4f+Gwoa7LLJO9FTDHGNBljdljbPUAVY6vAxeRnIpLDfVrL+cUIAzwnIttF5Hq7i7FZvjGmydpuBvLtLCYMfFNEdlnDNjExHAEgImXAGuAdYvQzEcnhrj5ypjFmLWNDVDeIyNl2FxQOzNg831ie63sHsAgoB5qAn9laTYiISCrwGHCTMcYz/r5Y+kxEcrjrcn4WY0yD9bUF+D1jQ1ax6oiIFAJYX1tsrsc2xpgjxphRY4wPuIsY+FyISDxjwf4bY8zj1u6Y/ExEcrjrcn6AiLhEJM2/DVwE7D7xd0W1J4FrrO1rgCdsrMVW/kCzfI4o/1yIiAD3AFXGmH8bd1dMfiYi+gpVa2rXz/loOb9/sbei0BORhYwdrcPYyloPxsr7ICIPAecy1tL1CPBD4A/AI8B8xtpIX2GMifoTjZO8F+cyNiRjgDrgL8eNPUcdETkTeB34APBZu3/A2Lh77H0mIjnclVJKTSySh2WUUkpNQsNdKaWikIa7UkpFIQ13pZSKQhruSikVhTTcVUwSkbLxHRSVijYa7koFiIjE2V2DUn4a7iqWOUXkLqv393Mikiwi5SKyxWq29Xt/sy0ReUVEKqztXBGps7a/KiJPishLjLWTVSosaLirWLYEuN0YsxLoAr4APAB8zxhzCmNXOv5wGs+zFthsjDknWIUqNVMa7iqW1Rpjdlrb2xnroJhpjHnV2nc/MJ0Om8/HwuXsKrJouKtYNjhuexTIPMFjR/jo5yXpuPu8AaxJqYDQcFfqI91Ap4icZd3+MuA/iq8D1lnbm0Ncl1Izpmf3lTrWNcB/iUgKUAN8zdp/C/CItdLVn+0qTqnp0q6QSikVhXRYRimlopCGu1JKRSENd6WUikIa7kopFYU03JVSKgppuCulVBTScFdKqSj0/wGekvAyHKwSUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.3 - \"workingday\"=1 escriba su código y hallazgos \n",
    "bikes_2 = bikes[bikes[\"workingday\"] == 1]\n",
    "bikes_2.groupby(by='hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Regresión lineal\n",
    "En la celda 3 ajuste un modelo de regresión lineal a todo el conjunto de datos, utilizando \"total\" como variable de respuesta y \"hour\" y \"workingday\" como las únicas variables predictoras. Luego, imprima los coeficientes e interprételos. ¿Cuáles son las limitaciones de la regresión lineal en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XTotal,YTotal = bikes.drop(columns='total').values, bikes['total'].values\n",
    "feature_cols = bikes.columns\n",
    "#print(feature_cols)\n",
    "feature_cols2=feature_cols.drop(\"total\")\n",
    "#print(feature_cols2)\n",
    "\n",
    "X = bikes[feature_cols2]\n",
    "#print(X)\n",
    "y = bikes[\"total\"]\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
       "       'humidity', 'windspeed', 'casual', 'registered', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workingday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     workingday  hour\n",
       "datetime                             \n",
       "2011-01-01 00:00:00           0     0\n",
       "2011-01-01 01:00:00           0     1\n",
       "2011-01-01 02:00:00           0     2\n",
       "2011-01-01 03:00:00           0     3\n",
       "2011-01-01 04:00:00           0     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los coeficientes estimados son:\n",
      "[ 6.71933431 10.55470277]\n",
      "El inconveniente que observo es que el coeficiente asociado a \"Workinday2\" se anularia inmediatamente para parte de las observaciones pues es una variable que asume valores binarios, es decir, o siempre da el valor del coeficiente o se multiplica por 0 dando \"0\", esto afecta la interpretacion del modelo y la regresion lineal no es trabajable con variables categoricas\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "\n",
    "#Regresion Lineal Simple\n",
    "\n",
    "X.drop(['holiday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered','season'], axis=1, inplace=True)\n",
    "display(X.head())\n",
    "\n",
    "#dividimos los datos en el conjunto de entrenamiento y el conjunto de pruebas\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n",
    "\n",
    "#Cargamos el conjunto de entrenamiento al modelo de Regresión Lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train, y_train)\n",
    "print('Los coeficientes estimados son:')\n",
    "print(regressor.coef_)\n",
    "\n",
    "\n",
    "print('El inconveniente que observo es que el coeficiente asociado a \"Workinday2\" se anularia inmediatamente para parte de las observaciones pues es una variable que asume valores binarios, es decir, o siempre da el valor del coeficiente o se multiplica por 0 dando \"0\", esto afecta la interpretacion del modelo y la regresion lineal no es trabajable con variables categoricas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Árbol de decisión manual\n",
    "En la celda 4 cree un árbol de decisiones para pronosticar la variable \"total\" iterando **manualmente** sobre las variables \"hour\" y  \"workingday\". El árbol debe tener al menos 6 nodos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed', 'casual', 'registered', 'hour'],\n",
      "      dtype='object')\n",
      "                     season  holiday  workingday  weather   temp   atemp  \\\n",
      "datetime                                                                   \n",
      "2011-01-01 00:00:00       1        0           0        1   9.84  14.395   \n",
      "2011-01-01 01:00:00       1        0           0        1   9.02  13.635   \n",
      "2011-01-01 02:00:00       1        0           0        1   9.02  13.635   \n",
      "2011-01-01 03:00:00       1        0           0        1   9.84  14.395   \n",
      "2011-01-01 04:00:00       1        0           0        1   9.84  14.395   \n",
      "...                     ...      ...         ...      ...    ...     ...   \n",
      "2012-12-19 19:00:00       4        0           1        1  15.58  19.695   \n",
      "2012-12-19 20:00:00       4        0           1        1  14.76  17.425   \n",
      "2012-12-19 21:00:00       4        0           1        1  13.94  15.910   \n",
      "2012-12-19 22:00:00       4        0           1        1  13.94  17.425   \n",
      "2012-12-19 23:00:00       4        0           1        1  13.12  16.665   \n",
      "\n",
      "                     humidity  windspeed  casual  registered  hour  \n",
      "datetime                                                            \n",
      "2011-01-01 00:00:00        81     0.0000       3          13     0  \n",
      "2011-01-01 01:00:00        80     0.0000       8          32     1  \n",
      "2011-01-01 02:00:00        80     0.0000       5          27     2  \n",
      "2011-01-01 03:00:00        75     0.0000       3          10     3  \n",
      "2011-01-01 04:00:00        75     0.0000       0           1     4  \n",
      "...                       ...        ...     ...         ...   ...  \n",
      "2012-12-19 19:00:00        50    26.0027       7         329    19  \n",
      "2012-12-19 20:00:00        57    15.0013      10         231    20  \n",
      "2012-12-19 21:00:00        61    15.0013       4         164    21  \n",
      "2012-12-19 22:00:00        61     6.0032      12         117    22  \n",
      "2012-12-19 23:00:00        66     8.9981       4          84    23  \n",
      "\n",
      "[10886 rows x 11 columns]\n",
      "datetime\n",
      "2011-01-01 00:00:00     16\n",
      "2011-01-01 01:00:00     40\n",
      "2011-01-01 02:00:00     32\n",
      "2011-01-01 03:00:00     13\n",
      "2011-01-01 04:00:00      1\n",
      "                      ... \n",
      "2012-12-19 19:00:00    336\n",
      "2012-12-19 20:00:00    241\n",
      "2012-12-19 21:00:00    168\n",
      "2012-12-19 22:00:00    129\n",
      "2012-12-19 23:00:00     88\n",
      "Name: total, Length: 10886, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Celda 4\n",
    "\n",
    "#Visualizar informacion\n",
    "# Gráfica del salario, años y hits\n",
    "#%matplotlib inline\n",
    "#plt.style.use('fivethirtyeight')\n",
    "#bikes.plot(kind='scatter', x='hour', y='total', colormap='jet', xlim=(0, 23), ylim=(0, 2000))\n",
    "\n",
    "feature_cols = bikes.columns\n",
    "#print(feature_cols)\n",
    "feature_cols2=feature_cols.drop(\"total\")\n",
    "#print(feature_cols2)\n",
    "\n",
    "X = bikes[feature_cols2]\n",
    "print(feature_cols2)\n",
    "print(X)\n",
    "y = bikes[\"total\"]\n",
    "print(y)\n",
    "\n",
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = 6\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para la primera variable ('hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour\n"
     ]
    }
   ],
   "source": [
    "# Impresión variable a usar (hour)\n",
    "j = 10\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  7.,  9., 12., 14., 16., 19., 21.])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de la variable hour en num_ctp puntos (parámetro definido anteriormente) para obtener posibles puntos de corte\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())\n",
    "splits = np.unique(splits)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2011-01-01 03:00:00    13\n",
      "2011-01-01 04:00:00     1\n",
      "2011-01-01 05:00:00     1\n",
      "2011-01-01 06:00:00     2\n",
      "2011-01-01 07:00:00     3\n",
      "                       ..\n",
      "2012-12-18 03:00:00     5\n",
      "2012-12-18 04:00:00     8\n",
      "2012-12-19 02:00:00     3\n",
      "2012-12-19 03:00:00     5\n",
      "2012-12-19 04:00:00     7\n",
      "Name: total, Length: 1530, dtype: int64\n",
      "datetime\n",
      "2011-01-01 00:00:00     16\n",
      "2011-01-01 01:00:00     40\n",
      "2011-01-01 02:00:00     32\n",
      "2011-01-01 10:00:00     36\n",
      "2011-01-01 11:00:00     56\n",
      "                      ... \n",
      "2012-12-19 19:00:00    336\n",
      "2012-12-19 20:00:00    241\n",
      "2012-12-19 21:00:00    168\n",
      "2012-12-19 22:00:00    129\n",
      "2012-12-19 23:00:00     88\n",
      "Name: total, Length: 9356, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# División de las observaciones usando el punto de corte en la posición 5 de la lista de splits\n",
    "k=5\n",
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "#print(filter_l)\n",
    "\n",
    "\n",
    "# División de la variable de respuesta de acuerdo a si la observación cumple o no con la regla binaria\n",
    "# y_l: la observación tiene un valor menor al punto de corte seleccionado\n",
    "# y_r: la observación tiene un valor mayor o igual al punto de corte seleccionado\n",
    "y_l = y.loc[filter_l]\n",
    "print(y_l)\n",
    "y_r = y.loc[~filter_l]\n",
    "print(y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función que calcula el gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27775.88300816515"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini index de las observaciones que tienen un valor menor al punto de corte seleccionado\n",
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-138889.2339678902"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini index de las observaciones que tienen un valor mayor o igual al punto de corte seleccionado\n",
    "gini_r = gini(y_r)\n",
    "gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función gini_imputiry para calular la ganancia de una variable predictora j dado el punto de corte k\n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10610.413579790038"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ganancia de la variable 'Hour' en el punto de corte selecionado\n",
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de cortepara hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 182.0, 42667.63221204425)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención de la variable 'j', su punto de corte 'split' y su ganancia 'gain'\n",
    "j, split, gain = best_split(X, y, 5)\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando la mejor variable 'j' y su punto de corte 'split'\n",
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 7252, 3634)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191.57413191254824, 88.17953667953668, 397.90809025866815)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=6, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 191.53903379867745,\n",
       " 'level': 0,\n",
       " 'split': [9, 210.0],\n",
       " 'n_samples': 10886,\n",
       " 'gain': 42946.30310163919,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 101.47880551689232,\n",
       "  'level': 1,\n",
       "  'split': [9, 84.0],\n",
       "  'n_samples': 7901,\n",
       "  'gain': 10229.734265240404,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 35.82280251806948,\n",
       "   'level': 2,\n",
       "   'split': [9, 36.0],\n",
       "   'n_samples': 4287,\n",
       "   'gain': 1417.4016710300734,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 15.48984865263935,\n",
       "    'level': 3,\n",
       "    'split': [9, 15.0],\n",
       "    'n_samples': 2707,\n",
       "    'gain': 207.8394934468132,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 7.68384074941452,\n",
       "     'level': 4,\n",
       "     'split': [9, 7.0],\n",
       "     'n_samples': 1706,\n",
       "     'gain': 28.574017013587437,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 4.573110893032385,\n",
       "      'level': 5,\n",
       "      'split': [9, 4.0],\n",
       "      'n_samples': 1017,\n",
       "      'gain': 6.0713227593588925,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 2.782696177062374,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 495,\n",
       "       'gain': 2.6014129424829093},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 6.255725190839694,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 522,\n",
       "       'gain': 6.031634884984072}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 12.250361794500723,\n",
       "      'level': 5,\n",
       "      'split': [8, 4.0],\n",
       "      'n_samples': 689,\n",
       "      'gain': 10.761256769948545,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 10.94296577946768,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 524,\n",
       "       'gain': 8.446605106278327},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 16.227544910179642,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 165,\n",
       "       'gain': 13.61878384947903}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 28.75274177467597,\n",
       "     'level': 4,\n",
       "     'split': [9, 24.0],\n",
       "     'n_samples': 1001,\n",
       "     'gain': 66.08538959605994,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 22.942,\n",
       "      'level': 5,\n",
       "      'split': [8, 7.0],\n",
       "      'n_samples': 498,\n",
       "      'gain': 25.584211303681514,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 21.0559796437659,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 391,\n",
       "       'gain': 10.918561577235096},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 29.3302752293578,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 107,\n",
       "       'gain': 23.028607570108534}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 34.394059405940595,\n",
       "      'level': 5,\n",
       "      'split': [8, 10.0],\n",
       "      'n_samples': 503,\n",
       "      'gain': 43.76879881213699,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 32.04197530864197,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 403,\n",
       "       'gain': 19.410642475496388},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 43.068627450980394,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 100,\n",
       "       'gain': 27.009165039179607}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 70.5960809102402,\n",
       "    'level': 3,\n",
       "    'split': [9, 61.0],\n",
       "    'n_samples': 1580,\n",
       "    'gain': 435.1050706854476,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 56.77777777777778,\n",
       "     'level': 4,\n",
       "     'split': [8, 12.0],\n",
       "     'n_samples': 844,\n",
       "     'gain': 120.64864157420834,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 51.81622516556291,\n",
       "      'level': 5,\n",
       "      'split': [9, 50.0],\n",
       "      'n_samples': 602,\n",
       "      'gain': 79.47791632975441,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 46.924083769633505,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 380,\n",
       "       'gain': 26.863428764376295},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 59.700892857142854,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 222,\n",
       "       'gain': 15.869325995596228}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 68.59836065573771,\n",
       "      'level': 5,\n",
       "      'split': [8, 21.0],\n",
       "      'n_samples': 242,\n",
       "      'gain': 109.54894026929651,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 63.80681818181818,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 174,\n",
       "       'gain': 69.08276001140439},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 78.7,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 68,\n",
       "       'gain': 76.15384615384573}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 86.24661246612466,\n",
       "     'level': 4,\n",
       "     'split': [8, 20.0],\n",
       "     'n_samples': 736,\n",
       "     'gain': 249.0423557144386,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 79.24953095684803,\n",
       "      'level': 5,\n",
       "      'split': [9, 74.0],\n",
       "      'n_samples': 531,\n",
       "      'gain': 75.21250536389744,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 74.14814814814815,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 322,\n",
       "       'gain': 40.62634152226747},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 86.33649289099526,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 209,\n",
       "       'gain': 39.855264468104}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 103.43478260869566,\n",
       "      'level': 5,\n",
       "      'split': [8, 33.0],\n",
       "      'n_samples': 205,\n",
       "      'gain': 234.13347221564254,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 95.97931034482758,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 143,\n",
       "       'gain': 66.97512867862679},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 117.109375,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 62,\n",
       "       'gain': 237.51027803640318}}}}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 179.2986725663717,\n",
       "   'level': 2,\n",
       "   'split': [9, 145.0],\n",
       "   'n_samples': 3614,\n",
       "   'gain': 3424.665613251149,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 141.0706243602866,\n",
       "    'level': 3,\n",
       "    'split': [8, 37.0],\n",
       "    'n_samples': 1952,\n",
       "    'gain': 1055.1492001386723,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 126.63007840342124,\n",
       "     'level': 4,\n",
       "     'split': [9, 112.0],\n",
       "     'n_samples': 1401,\n",
       "     'gain': 521.5987874847633,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 111.33646112600536,\n",
       "      'level': 5,\n",
       "      'split': [8, 15.0],\n",
       "      'n_samples': 744,\n",
       "      'gain': 147.85949826851356,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 103.26044226044226,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 405,\n",
       "       'gain': 113.22538557263033},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 120.32551319648094,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 339,\n",
       "       'gain': 78.25507263106556}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 143.5599393019727,\n",
       "      'level': 5,\n",
       "      'split': [8, 20.0],\n",
       "      'n_samples': 657,\n",
       "      'gain': 174.37182772719098,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 136.03658536585365,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 408,\n",
       "       'gain': 147.58224080483342},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 154.70916334661354,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 249,\n",
       "       'gain': 149.93540181084245}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 177.1989150090416,\n",
       "     'level': 4,\n",
       "     'split': [8, 90.0],\n",
       "     'n_samples': 551,\n",
       "     'gain': 1034.7042106138979,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 169.898406374502,\n",
       "      'level': 5,\n",
       "      'split': [9, 116.0],\n",
       "      'n_samples': 500,\n",
       "      'gain': 480.5282605981556,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 151.94222222222223,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 223,\n",
       "       'gain': 205.17437857373443},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 183.16487455197134,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 277,\n",
       "       'gain': 228.54949187782768}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 239.67924528301887,\n",
       "      'level': 5,\n",
       "      'split': [8, 116.63636363636363],\n",
       "      'n_samples': 51,\n",
       "      'gain': 1811.0460572975862,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 207.03333333333333,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 28,\n",
       "       'gain': 528.7989195678383},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 259.72,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 23,\n",
       "       'gain': 962.5843910343247}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 223.97415865384616,\n",
       "    'level': 3,\n",
       "    'split': [8, 64.0],\n",
       "    'n_samples': 1662,\n",
       "    'gain': 2341.9449945985107,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 202.9297520661157,\n",
       "     'level': 4,\n",
       "     'split': [9, 175.0],\n",
       "     'n_samples': 1208,\n",
       "     'gain': 539.4781366364914,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 187.6027397260274,\n",
       "      'level': 5,\n",
       "      'split': [8, 30.0],\n",
       "      'n_samples': 655,\n",
       "      'gain': 493.3805322740809,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 172.4814814814815,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 349,\n",
       "       'gain': 115.09336747805355},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 203.62012987012986,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 306,\n",
       "       'gain': 191.1406610716367}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 220.34414414414414,\n",
       "      'level': 5,\n",
       "      'split': [8, 36.0],\n",
       "      'n_samples': 553,\n",
       "      'gain': 400.0252151122986,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 209.17613636363637,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 350,\n",
       "       'gain': 144.93364644060784},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 237.37560975609756,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 203,\n",
       "       'gain': 181.95921577913396}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 278.8355263157895,\n",
       "     'level': 4,\n",
       "     'split': [8, 125.90909090909105],\n",
       "     'n_samples': 454,\n",
       "     'gain': 2367.027110032126,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 262.3780160857909,\n",
       "      'level': 5,\n",
       "      'split': [9, 183.0],\n",
       "      'n_samples': 371,\n",
       "      'gain': 568.6831261447223,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 245.06153846153848,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 193,\n",
       "       'gain': 357.6101308307552},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 278.22777777777776,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 178,\n",
       "       'gain': 404.40561580768554}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 344.50588235294117,\n",
       "      'level': 5,\n",
       "      'split': [8, 170.0],\n",
       "      'n_samples': 83,\n",
       "      'gain': 1794.9313479379052,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 310.5,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 44,\n",
       "       'gain': 489.6846074380155},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 365.8780487804878,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 39,\n",
       "       'gain': 800.9568892645766}}}}}},\n",
       " 'sr': {'y_pred': 1,\n",
       "  'y_prob': 429.692333444928,\n",
       "  'level': 1,\n",
       "  'split': [9, 464.4545454545455],\n",
       "  'n_samples': 2985,\n",
       "  'gain': 23450.232949455967,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 378.60965630114566,\n",
       "   'level': 2,\n",
       "   'split': [8, 143.0],\n",
       "   'n_samples': 2442,\n",
       "   'gain': 8223.835623411986,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 348.1758517034068,\n",
       "    'level': 3,\n",
       "    'split': [9, 310.0],\n",
       "    'n_samples': 1994,\n",
       "    'gain': 6321.801829707954,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 305.4554767533491,\n",
       "     'level': 4,\n",
       "     'split': [8, 64.0],\n",
       "     'n_samples': 1267,\n",
       "     'gain': 1913.6724354332255,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 281.80421313506815,\n",
       "      'level': 5,\n",
       "      'split': [9, 252.0],\n",
       "      'n_samples': 805,\n",
       "      'gain': 1040.0807024941605,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 259.88837209302324,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 428,\n",
       "       'gain': 559.7153985188343},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 305.18469656992085,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 377,\n",
       "       'gain': 426.00055471766973}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 345.2758620689655,\n",
       "      'level': 5,\n",
       "      'split': [9, 249.45454545454544],\n",
       "      'n_samples': 462,\n",
       "      'gain': 847.552976893232,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 325.3976377952756,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 252,\n",
       "       'gain': 878.2573944570613},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 365.83962264150944,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 210,\n",
       "       'gain': 710.3249152416829}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 421.5871056241427,\n",
       "     'level': 4,\n",
       "     'split': [9, 408.0],\n",
       "     'n_samples': 727,\n",
       "     'gain': 2530.7121548436116,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 399.08365019011404,\n",
       "      'level': 5,\n",
       "      'split': [8, 69.0],\n",
       "      'n_samples': 524,\n",
       "      'gain': 1572.057672136114,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 381.0791556728232,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 377,\n",
       "       'gain': 939.2844340939773},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 439.5302013422819,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 147,\n",
       "       'gain': 855.3815244172001}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 475.219512195122,\n",
       "      'level': 5,\n",
       "      'split': [8, 52.0],\n",
       "      'n_samples': 203,\n",
       "      'gain': 1313.6405715572182,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 452.94573643410854,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 127,\n",
       "       'gain': 430.470347760187},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 499.88461538461536,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 76,\n",
       "       'gain': 509.07852060499135}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 511.92,\n",
       "    'level': 3,\n",
       "    'split': [9, 299.0],\n",
       "    'n_samples': 448,\n",
       "    'gain': 8482.017077737954,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 438.0049019607843,\n",
       "     'level': 4,\n",
       "     'split': [8, 191.0],\n",
       "     'n_samples': 202,\n",
       "     'gain': 2538.6581914054113,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 408.1953125,\n",
       "      'level': 5,\n",
       "      'split': [9, 254.0],\n",
       "      'n_samples': 126,\n",
       "      'gain': 1098.7571183629334,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 381.30434782608694,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 67,\n",
       "       'gain': 391.2349658955354},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 425.24590163934425,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 59,\n",
       "       'gain': 329.68306521116756}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 475.70512820512823,\n",
       "      'level': 5,\n",
       "      'split': [8, 285.18181818181824],\n",
       "      'n_samples': 76,\n",
       "      'gain': 2215.8623217081768,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 464.16901408450707,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 69,\n",
       "       'gain': 751.2172400755808},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 461.1111111111111,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 7,\n",
       "       'gain': 1053.3224489798304}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 568.5967741935484,\n",
       "     'level': 4,\n",
       "     'split': [8, 226.63636363636363],\n",
       "     'n_samples': 246,\n",
       "     'gain': 5198.6795097696595,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 518.8676470588235,\n",
       "      'level': 5,\n",
       "      'split': [9, 350.6363636363636],\n",
       "      'n_samples': 134,\n",
       "      'gain': 1672.6898117231904,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 493.0574712643678,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 85,\n",
       "       'gain': 872.7664727101219},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 542.5686274509804,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 49,\n",
       "       'gain': 796.1412388498429}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 617.9561403508771,\n",
       "      'level': 5,\n",
       "      'split': [9, 366.0],\n",
       "      'n_samples': 112,\n",
       "      'gain': 2570.476780512603,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 583.7746478873239,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 69,\n",
       "       'gain': 1828.8681116983062},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 644.4444444444445,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 43,\n",
       "       'gain': 1399.7902993188472}}}}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 657.1926605504588,\n",
       "   'level': 2,\n",
       "   'split': [9, 638.9090909090909],\n",
       "   'n_samples': 543,\n",
       "   'gain': 18197.971913816407,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 583.9654178674351,\n",
       "    'level': 3,\n",
       "    'split': [9, 547.0],\n",
       "    'n_samples': 345,\n",
       "    'gain': 3641.3732908351813,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 549.7409090909091,\n",
       "     'level': 4,\n",
       "     'split': [8, 46.0],\n",
       "     'n_samples': 218,\n",
       "     'gain': 1689.0239349884214,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 512.18,\n",
       "      'level': 5,\n",
       "      'split': [9, 507.72727272727275],\n",
       "      'n_samples': 98,\n",
       "      'gain': 1017.4605398885906,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 489.65625,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 62,\n",
       "       'gain': 158.15402678132523},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 523.1842105263158,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 36,\n",
       "       'gain': 474.9225810376229}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 571.5245901639345,\n",
       "      'level': 5,\n",
       "      'split': [8, 104.0],\n",
       "      'n_samples': 120,\n",
       "      'gain': 1453.503472222248,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 561.6636363636363,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 108,\n",
       "       'gain': 857.4108685534447},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 567.4285714285714,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 12,\n",
       "       'gain': 3402.7777777778683}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 633.2868217054264,\n",
       "     'level': 4,\n",
       "     'split': [8, 76.0],\n",
       "     'n_samples': 127,\n",
       "     'gain': 1468.4866778084543,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 612.752688172043,\n",
       "      'level': 5,\n",
       "      'split': [9, 595.0],\n",
       "      'n_samples': 91,\n",
       "      'gain': 1138.2151971522253,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 580.4509803921569,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 49,\n",
       "       'gain': 472.7121275225654},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 622.3636363636364,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 42,\n",
       "       'gain': 419.27437641716097}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 650.2368421052631,\n",
       "      'level': 5,\n",
       "      'split': [9, 566.7272727272727],\n",
       "      'n_samples': 36,\n",
       "      'gain': 1380.7276105534984,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 564.6,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 13,\n",
       "       'gain': 377.77251808019355},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 649.64,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 23,\n",
       "       'gain': 468.6971959673101}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 777.675,\n",
       "    'level': 3,\n",
       "    'split': [9, 733.0],\n",
       "    'n_samples': 198,\n",
       "    'gain': 5989.525000896072,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 731.4603174603175,\n",
       "     'level': 4,\n",
       "     'split': [8, 72.4545454545454],\n",
       "     'n_samples': 124,\n",
       "     'gain': 2812.2878151261248,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 688.9714285714285,\n",
       "      'level': 5,\n",
       "      'split': [9, 678.9090909090909],\n",
       "      'n_samples': 68,\n",
       "      'gain': 1090.1725311820628,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 660.7111111111111,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 43,\n",
       "       'gain': 448.650487361243},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 685.074074074074,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 25,\n",
       "       'gain': 482.7760222221259}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 757.5344827586207,\n",
       "      'level': 5,\n",
       "      'split': [9, 688.0],\n",
       "      'n_samples': 56,\n",
       "      'gain': 1131.1693222746253,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 722.9444444444445,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 34,\n",
       "       'gain': 458.5970011530444},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 746.3333333333334,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 22,\n",
       "       'gain': 283.9092384886462}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 833.8421052631579,\n",
       "     'level': 4,\n",
       "     'split': [8, 81.0909090909091],\n",
       "     'n_samples': 74,\n",
       "     'gain': 1383.2788881461602,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 765.0344827586207,\n",
       "      'level': 5,\n",
       "      'split': [9, 781.9090909090909],\n",
       "      'n_samples': 27,\n",
       "      'gain': 921.6900584795512,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 730.8571428571429,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 19,\n",
       "       'gain': 339.66149584483355},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 683.9,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 8,\n",
       "       'gain': 672.0416666665114}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 840.5510204081633,\n",
       "      'level': 5,\n",
       "      'split': [9, 792.5454545454545],\n",
       "      'n_samples': 47,\n",
       "      'gain': 1688.3734959850553,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 819.075,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 38,\n",
       "       'gain': 292.801015696954},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 765.9090909090909,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 9,\n",
       "       'gain': 1469.4444444442634}}}}}}}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicación de la función tree_grow\n",
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=6, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 191.53903379867745,\n",
       " 'level': 0,\n",
       " 'split': [9, 210.0],\n",
       " 'n_samples': 10886,\n",
       " 'gain': 42946.30310163919,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 101.47880551689232,\n",
       "  'level': 1,\n",
       "  'split': [9, 84.0],\n",
       "  'n_samples': 7901,\n",
       "  'gain': 10229.734265240404,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 35.82280251806948,\n",
       "   'level': 2,\n",
       "   'split': [9, 36.0],\n",
       "   'n_samples': 4287,\n",
       "   'gain': 1417.4016710300734,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 15.48984865263935,\n",
       "    'level': 3,\n",
       "    'split': [9, 15.0],\n",
       "    'n_samples': 2707,\n",
       "    'gain': 207.8394934468132,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 7.68384074941452,\n",
       "     'level': 4,\n",
       "     'split': [9, 7.0],\n",
       "     'n_samples': 1706,\n",
       "     'gain': 28.574017013587437,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 4.573110893032385,\n",
       "      'level': 5,\n",
       "      'split': [9, 4.0],\n",
       "      'n_samples': 1017,\n",
       "      'gain': 6.0713227593588925,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 2.782696177062374,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 495,\n",
       "       'gain': 2.6014129424829093},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 6.255725190839694,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 522,\n",
       "       'gain': 6.031634884984072}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 12.250361794500723,\n",
       "      'level': 5,\n",
       "      'split': [8, 4.0],\n",
       "      'n_samples': 689,\n",
       "      'gain': 10.761256769948545,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 10.94296577946768,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 524,\n",
       "       'gain': 8.446605106278327},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 16.227544910179642,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 165,\n",
       "       'gain': 13.61878384947903}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 28.75274177467597,\n",
       "     'level': 4,\n",
       "     'split': [9, 24.0],\n",
       "     'n_samples': 1001,\n",
       "     'gain': 66.08538959605994,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 22.942,\n",
       "      'level': 5,\n",
       "      'split': [8, 7.0],\n",
       "      'n_samples': 498,\n",
       "      'gain': 25.584211303681514,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 21.0559796437659,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 391,\n",
       "       'gain': 10.918561577235096},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 29.3302752293578,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 107,\n",
       "       'gain': 23.028607570108534}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 34.394059405940595,\n",
       "      'level': 5,\n",
       "      'split': [8, 10.0],\n",
       "      'n_samples': 503,\n",
       "      'gain': 43.76879881213699,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 32.04197530864197,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 403,\n",
       "       'gain': 19.410642475496388},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 43.068627450980394,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 100,\n",
       "       'gain': 27.009165039179607}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 70.5960809102402,\n",
       "    'level': 3,\n",
       "    'split': [9, 61.0],\n",
       "    'n_samples': 1580,\n",
       "    'gain': 435.1050706854476,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 56.77777777777778,\n",
       "     'level': 4,\n",
       "     'split': [8, 12.0],\n",
       "     'n_samples': 844,\n",
       "     'gain': 120.64864157420834,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 51.81622516556291,\n",
       "      'level': 5,\n",
       "      'split': [9, 50.0],\n",
       "      'n_samples': 602,\n",
       "      'gain': 79.47791632975441,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 46.924083769633505,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 380,\n",
       "       'gain': 26.863428764376295},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 59.700892857142854,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 222,\n",
       "       'gain': 15.869325995596228}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 68.59836065573771,\n",
       "      'level': 5,\n",
       "      'split': [8, 21.0],\n",
       "      'n_samples': 242,\n",
       "      'gain': 109.54894026929651,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 63.80681818181818,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 174,\n",
       "       'gain': 69.08276001140439},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 78.7,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 68,\n",
       "       'gain': 76.15384615384573}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 86.24661246612466,\n",
       "     'level': 4,\n",
       "     'split': [8, 20.0],\n",
       "     'n_samples': 736,\n",
       "     'gain': 249.0423557144386,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 79.24953095684803,\n",
       "      'level': 5,\n",
       "      'split': [9, 74.0],\n",
       "      'n_samples': 531,\n",
       "      'gain': 75.21250536389744,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 74.14814814814815,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 322,\n",
       "       'gain': 40.62634152226747},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 86.33649289099526,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 209,\n",
       "       'gain': 39.855264468104}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 103.43478260869566,\n",
       "      'level': 5,\n",
       "      'split': [8, 33.0],\n",
       "      'n_samples': 205,\n",
       "      'gain': 234.13347221564254,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 95.97931034482758,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 143,\n",
       "       'gain': 66.97512867862679},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 117.109375,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 62,\n",
       "       'gain': 237.51027803640318}}}}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 179.2986725663717,\n",
       "   'level': 2,\n",
       "   'split': [9, 145.0],\n",
       "   'n_samples': 3614,\n",
       "   'gain': 3424.665613251149,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 141.0706243602866,\n",
       "    'level': 3,\n",
       "    'split': [8, 37.0],\n",
       "    'n_samples': 1952,\n",
       "    'gain': 1055.1492001386723,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 126.63007840342124,\n",
       "     'level': 4,\n",
       "     'split': [9, 112.0],\n",
       "     'n_samples': 1401,\n",
       "     'gain': 521.5987874847633,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 111.33646112600536,\n",
       "      'level': 5,\n",
       "      'split': [8, 15.0],\n",
       "      'n_samples': 744,\n",
       "      'gain': 147.85949826851356,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 103.26044226044226,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 405,\n",
       "       'gain': 113.22538557263033},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 120.32551319648094,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 339,\n",
       "       'gain': 78.25507263106556}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 143.5599393019727,\n",
       "      'level': 5,\n",
       "      'split': [8, 20.0],\n",
       "      'n_samples': 657,\n",
       "      'gain': 174.37182772719098,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 136.03658536585365,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 408,\n",
       "       'gain': 147.58224080483342},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 154.70916334661354,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 249,\n",
       "       'gain': 149.93540181084245}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 177.1989150090416,\n",
       "     'level': 4,\n",
       "     'split': [8, 90.0],\n",
       "     'n_samples': 551,\n",
       "     'gain': 1034.7042106138979,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 169.898406374502,\n",
       "      'level': 5,\n",
       "      'split': [9, 116.0],\n",
       "      'n_samples': 500,\n",
       "      'gain': 480.5282605981556,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 151.94222222222223,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 223,\n",
       "       'gain': 205.17437857373443},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 183.16487455197134,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 277,\n",
       "       'gain': 228.54949187782768}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 239.67924528301887,\n",
       "      'level': 5,\n",
       "      'split': [8, 116.63636363636363],\n",
       "      'n_samples': 51,\n",
       "      'gain': 1811.0460572975862,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 207.03333333333333,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 28,\n",
       "       'gain': 528.7989195678383},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 259.72,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 23,\n",
       "       'gain': 962.5843910343247}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 223.97415865384616,\n",
       "    'level': 3,\n",
       "    'split': [8, 64.0],\n",
       "    'n_samples': 1662,\n",
       "    'gain': 2341.9449945985107,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 202.9297520661157,\n",
       "     'level': 4,\n",
       "     'split': [9, 175.0],\n",
       "     'n_samples': 1208,\n",
       "     'gain': 539.4781366364914,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 187.6027397260274,\n",
       "      'level': 5,\n",
       "      'split': [8, 30.0],\n",
       "      'n_samples': 655,\n",
       "      'gain': 493.3805322740809,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 172.4814814814815,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 349,\n",
       "       'gain': 115.09336747805355},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 203.62012987012986,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 306,\n",
       "       'gain': 191.1406610716367}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 220.34414414414414,\n",
       "      'level': 5,\n",
       "      'split': [8, 36.0],\n",
       "      'n_samples': 553,\n",
       "      'gain': 400.0252151122986,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 209.17613636363637,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 350,\n",
       "       'gain': 144.93364644060784},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 237.37560975609756,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 203,\n",
       "       'gain': 181.95921577913396}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 278.8355263157895,\n",
       "     'level': 4,\n",
       "     'split': [8, 125.90909090909105],\n",
       "     'n_samples': 454,\n",
       "     'gain': 2367.027110032126,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 262.3780160857909,\n",
       "      'level': 5,\n",
       "      'split': [9, 183.0],\n",
       "      'n_samples': 371,\n",
       "      'gain': 568.6831261447223,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 245.06153846153848,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 193,\n",
       "       'gain': 357.6101308307552},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 278.22777777777776,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 178,\n",
       "       'gain': 404.40561580768554}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 344.50588235294117,\n",
       "      'level': 5,\n",
       "      'split': [8, 170.0],\n",
       "      'n_samples': 83,\n",
       "      'gain': 1794.9313479379052,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 310.5,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 44,\n",
       "       'gain': 489.6846074380155},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 365.8780487804878,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 39,\n",
       "       'gain': 800.9568892645766}}}}}},\n",
       " 'sr': {'y_pred': 1,\n",
       "  'y_prob': 429.692333444928,\n",
       "  'level': 1,\n",
       "  'split': [9, 464.4545454545455],\n",
       "  'n_samples': 2985,\n",
       "  'gain': 23450.232949455967,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 378.60965630114566,\n",
       "   'level': 2,\n",
       "   'split': [8, 143.0],\n",
       "   'n_samples': 2442,\n",
       "   'gain': 8223.835623411986,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 348.1758517034068,\n",
       "    'level': 3,\n",
       "    'split': [9, 310.0],\n",
       "    'n_samples': 1994,\n",
       "    'gain': 6321.801829707954,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 305.4554767533491,\n",
       "     'level': 4,\n",
       "     'split': [8, 64.0],\n",
       "     'n_samples': 1267,\n",
       "     'gain': 1913.6724354332255,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 281.80421313506815,\n",
       "      'level': 5,\n",
       "      'split': [9, 252.0],\n",
       "      'n_samples': 805,\n",
       "      'gain': 1040.0807024941605,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 259.88837209302324,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 428,\n",
       "       'gain': 559.7153985188343},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 305.18469656992085,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 377,\n",
       "       'gain': 426.00055471766973}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 345.2758620689655,\n",
       "      'level': 5,\n",
       "      'split': [9, 249.45454545454544],\n",
       "      'n_samples': 462,\n",
       "      'gain': 847.552976893232,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 325.3976377952756,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 252,\n",
       "       'gain': 878.2573944570613},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 365.83962264150944,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 210,\n",
       "       'gain': 710.3249152416829}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 421.5871056241427,\n",
       "     'level': 4,\n",
       "     'split': [9, 408.0],\n",
       "     'n_samples': 727,\n",
       "     'gain': 2530.7121548436116,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 399.08365019011404,\n",
       "      'level': 5,\n",
       "      'split': [8, 69.0],\n",
       "      'n_samples': 524,\n",
       "      'gain': 1572.057672136114,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 381.0791556728232,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 377,\n",
       "       'gain': 939.2844340939773},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 439.5302013422819,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 147,\n",
       "       'gain': 855.3815244172001}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 475.219512195122,\n",
       "      'level': 5,\n",
       "      'split': [8, 52.0],\n",
       "      'n_samples': 203,\n",
       "      'gain': 1313.6405715572182,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 452.94573643410854,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 127,\n",
       "       'gain': 430.470347760187},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 499.88461538461536,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 76,\n",
       "       'gain': 509.07852060499135}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 511.92,\n",
       "    'level': 3,\n",
       "    'split': [9, 299.0],\n",
       "    'n_samples': 448,\n",
       "    'gain': 8482.017077737954,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 438.0049019607843,\n",
       "     'level': 4,\n",
       "     'split': [8, 191.0],\n",
       "     'n_samples': 202,\n",
       "     'gain': 2538.6581914054113,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 408.1953125,\n",
       "      'level': 5,\n",
       "      'split': [9, 254.0],\n",
       "      'n_samples': 126,\n",
       "      'gain': 1098.7571183629334,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 381.30434782608694,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 67,\n",
       "       'gain': 391.2349658955354},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 425.24590163934425,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 59,\n",
       "       'gain': 329.68306521116756}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 475.70512820512823,\n",
       "      'level': 5,\n",
       "      'split': [8, 285.18181818181824],\n",
       "      'n_samples': 76,\n",
       "      'gain': 2215.8623217081768,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 464.16901408450707,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 69,\n",
       "       'gain': 751.2172400755808},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 461.1111111111111,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 7,\n",
       "       'gain': 1053.3224489798304}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 568.5967741935484,\n",
       "     'level': 4,\n",
       "     'split': [8, 226.63636363636363],\n",
       "     'n_samples': 246,\n",
       "     'gain': 5198.6795097696595,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 518.8676470588235,\n",
       "      'level': 5,\n",
       "      'split': [9, 350.6363636363636],\n",
       "      'n_samples': 134,\n",
       "      'gain': 1672.6898117231904,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 493.0574712643678,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 85,\n",
       "       'gain': 872.7664727101219},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 542.5686274509804,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 49,\n",
       "       'gain': 796.1412388498429}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 617.9561403508771,\n",
       "      'level': 5,\n",
       "      'split': [9, 366.0],\n",
       "      'n_samples': 112,\n",
       "      'gain': 2570.476780512603,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 583.7746478873239,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 69,\n",
       "       'gain': 1828.8681116983062},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 644.4444444444445,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 43,\n",
       "       'gain': 1399.7902993188472}}}}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 657.1926605504588,\n",
       "   'level': 2,\n",
       "   'split': [9, 638.9090909090909],\n",
       "   'n_samples': 543,\n",
       "   'gain': 18197.971913816407,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 583.9654178674351,\n",
       "    'level': 3,\n",
       "    'split': [9, 547.0],\n",
       "    'n_samples': 345,\n",
       "    'gain': 3641.3732908351813,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 549.7409090909091,\n",
       "     'level': 4,\n",
       "     'split': [8, 46.0],\n",
       "     'n_samples': 218,\n",
       "     'gain': 1689.0239349884214,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 512.18,\n",
       "      'level': 5,\n",
       "      'split': [9, 507.72727272727275],\n",
       "      'n_samples': 98,\n",
       "      'gain': 1017.4605398885906,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 489.65625,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 62,\n",
       "       'gain': 158.15402678132523},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 523.1842105263158,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 36,\n",
       "       'gain': 474.9225810376229}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 571.5245901639345,\n",
       "      'level': 5,\n",
       "      'split': [8, 104.0],\n",
       "      'n_samples': 120,\n",
       "      'gain': 1453.503472222248,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 561.6636363636363,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 108,\n",
       "       'gain': 857.4108685534447},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 567.4285714285714,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 12,\n",
       "       'gain': 3402.7777777778683}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 633.2868217054264,\n",
       "     'level': 4,\n",
       "     'split': [8, 76.0],\n",
       "     'n_samples': 127,\n",
       "     'gain': 1468.4866778084543,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 612.752688172043,\n",
       "      'level': 5,\n",
       "      'split': [9, 595.0],\n",
       "      'n_samples': 91,\n",
       "      'gain': 1138.2151971522253,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 580.4509803921569,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 49,\n",
       "       'gain': 472.7121275225654},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 622.3636363636364,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 42,\n",
       "       'gain': 419.27437641716097}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 650.2368421052631,\n",
       "      'level': 5,\n",
       "      'split': [9, 566.7272727272727],\n",
       "      'n_samples': 36,\n",
       "      'gain': 1380.7276105534984,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 564.6,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 13,\n",
       "       'gain': 377.77251808019355},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 649.64,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 23,\n",
       "       'gain': 468.6971959673101}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 777.675,\n",
       "    'level': 3,\n",
       "    'split': [9, 733.0],\n",
       "    'n_samples': 198,\n",
       "    'gain': 5989.525000896072,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 731.4603174603175,\n",
       "     'level': 4,\n",
       "     'split': [8, 72.4545454545454],\n",
       "     'n_samples': 124,\n",
       "     'gain': 2812.2878151261248,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 688.9714285714285,\n",
       "      'level': 5,\n",
       "      'split': [9, 678.9090909090909],\n",
       "      'n_samples': 68,\n",
       "      'gain': 1090.1725311820628,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 660.7111111111111,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 43,\n",
       "       'gain': 448.650487361243},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 685.074074074074,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 25,\n",
       "       'gain': 482.7760222221259}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 757.5344827586207,\n",
       "      'level': 5,\n",
       "      'split': [9, 688.0],\n",
       "      'n_samples': 56,\n",
       "      'gain': 1131.1693222746253,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 722.9444444444445,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 34,\n",
       "       'gain': 458.5970011530444},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 746.3333333333334,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 22,\n",
       "       'gain': 283.9092384886462}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 833.8421052631579,\n",
       "     'level': 4,\n",
       "     'split': [8, 81.0909090909091],\n",
       "     'n_samples': 74,\n",
       "     'gain': 1383.2788881461602,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 765.0344827586207,\n",
       "      'level': 5,\n",
       "      'split': [9, 781.9090909090909],\n",
       "      'n_samples': 27,\n",
       "      'gain': 921.6900584795512,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 730.8571428571429,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 19,\n",
       "       'gain': 339.66149584483355},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 683.9,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 8,\n",
       "       'gain': 672.0416666665114}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 840.5510204081633,\n",
       "      'level': 5,\n",
       "      'split': [9, 792.5454545454545],\n",
       "      'n_samples': 47,\n",
       "      'gain': 1688.3734959850553,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 819.075,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 38,\n",
       "       'gain': 292.801015696954},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 765.9090909090909,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 9,\n",
       "       'gain': 1469.4444444442634}}}}}}}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X, y, level=0, min_gain=0.001, max_depth=6, num_pct=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones con el arbol creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree'\n",
    "\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecución de función tree_predict\n",
    "tree_predict(X, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para la segunda variable ('workingday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workingday\n"
     ]
    }
   ],
   "source": [
    "# Impresión variable a usar (Hits)\n",
    "j = 2\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de la variable Hits en num_ctp puntos (parámetro definido anteriormente) para obtener posibles puntos de corte\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())\n",
    "splits = np.unique(splits)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando el punto de corte en la posición 2 de la lista de splits\n",
    "k=1\n",
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "#print(filter_l)\n",
    "\n",
    "# División de la variable de respuesta de acuerdo a si la observación cumple o no con la regla binaria\n",
    "# y_l: la observación tiene un valor menor al punto de corte seleccionado\n",
    "# y_r: la observación tiene un valor mayor o igual al punto de corte seleccionado\n",
    "y_l = y.loc[filter_l]\n",
    "#print(y_l)\n",
    "y_r = y.loc[~filter_l]\n",
    "#print(y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función que calcula el gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-70692.47878657113"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini index de las observaciones que tienen un valor menor al punto de corte seleccionado\n",
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Árbol de decisión con librería\n",
    "En la celda 5 entrene un árbol de decisiones con la **librería sklearn**, usando las variables predictoras \"hour\" y \"workingday\" y calibre los parámetros que considere conveniente para obtener un mejor desempeño. Comente el desempeño del modelo con alguna métrica de desempeño de modelos de clasificación y compare desempeño con el modelo del punto 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n",
    "# Lista de valores para calibrar el criterio de parada de máxima profundidad (max_depth)\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# Lista para guardar los valores del RMSE para cada valor de máxima profundidad (max_depth)\n",
    "accuracy_scores = []\n",
    "\n",
    "# Importación de modelos de sklearn \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loop para obtener el desempeño del modelo de acuerdo con la máxima profundidad\n",
    "for depth in max_depth_range:\n",
    "    # Definición del árbol de decisión usando DecisionTreeClassifier de la libreria sklearn\n",
    "    clf = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Gráfica max_depth versus RMSE (error del modelo)\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1338426038459461, 20)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mejor accuracy (desempeño del modelo) y su correspondiente max_depth\n",
    "sorted(zip(accuracy_scores, max_depth_range))[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=6, random_state=1)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_depth=4 fue el mejor, se ajusta un árbol usando este valor \n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>season</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>holiday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>workingday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weather</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atemp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>casual</td>\n",
       "      <td>0.411589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>registered</td>\n",
       "      <td>0.588411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0       season    0.000000\n",
       "1      holiday    0.000000\n",
       "2   workingday    0.000000\n",
       "3      weather    0.000000\n",
       "4         temp    0.000000\n",
       "5        atemp    0.000000\n",
       "6     humidity    0.000000\n",
       "7    windspeed    0.000000\n",
       "10        hour    0.000000\n",
       "8       casual    0.411589\n",
       "9   registered    0.588411"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uso de la función .feature_importances_ para obtener la importancia de cada variable\n",
    "pd.DataFrame({'feature':feature_cols2, 'importance':clf.feature_importances_}).sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.133843\n",
       "std       0.006561\n",
       "min       0.123967\n",
       "25%       0.130285\n",
       "50%       0.134068\n",
       "75%       0.138526\n",
       "max       0.144301\n",
       "dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión de resultados de desemepeño del árbol de decisión\n",
    "pd.Series(cross_val_score(clf, X, y, cv=10)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Métodos de ensamblajes\n",
    "En esta parte del taller se usará el conjunto de datos de Popularidad de Noticias Online. El objetivo es predecir si la notica es popular o no, la populridad esta dada por la cantidad de reacciones en redes sociales. Para más detalles puede visitar el sigueinte enlace: [datos](https://archive.ics.uci.edu/ml/datasets/online+news+popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos popularidad de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.844262        5.0             1.0       1.0  ...   \n",
       "1                  0.815789        9.0             4.0       1.0  ...   \n",
       "2                  0.775701        4.0             3.0       1.0  ...   \n",
       "3                  0.677350       10.0             3.0       1.0  ...   \n",
       "4                  0.830357        3.0             2.0       1.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Lectura de la información de archivo .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición variable de interes y variables predictoras\n",
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483    0\n",
       "2185    1\n",
       "2520    0\n",
       "3721    1\n",
       "3727    0\n",
       "Name: Popular, dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de la muestra en set de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - Árbol de decisión y regresión logística\n",
    "En la celda 6 construya un árbol de decisión y una regresión logística. Para el árbol calibre al menos un parámetro y evalúe el desempeño de cada modelo usando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacion Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Definición de 4 modelos diferentes: regresión logística, árbol de decisión,Navie Bayes y k vecinos más cercanos\n",
    "models = {'lr': LogisticRegression(),\n",
    "          'dt': DecisionTreeRegressor()\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento (fit) de cada modelo\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lr   dt\n",
      "1483  NaN  NaN\n",
      "2185  NaN  NaN\n",
      "2520  NaN  NaN\n",
      "3721  NaN  NaN\n",
      "3727  NaN  NaN\n",
      "...   ...  ...\n",
      "3077  NaN  NaN\n",
      "5166  NaN  NaN\n",
      "2227  NaN  NaN\n",
      "5684  NaN  NaN\n",
      "1937  NaN  NaN\n",
      "\n",
      "[1500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predicción de las observaciones del set de test para cada modelo\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=models.keys())\n",
    "print(y_pred)\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.6212889826803627\n",
      "dt 0.6797058187186572\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del error de cada modelo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(mean_squared_error(y_pred[model], y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediccionesRegLog=clfRegLog.predict(X_test)\n",
    "prediccionesProbRegLog=clfRegLog.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5680375574437545"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación  del error promedio de las predicciones\n",
    "np.sqrt(mean_squared_error(y_pred.mean(axis=1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arreglo: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Muestreo aleatorio:  [ 6 12 13  9 10 12  6 16  1 17  2 13  8 14  7 19  6 19 12 11]\n"
     ]
    }
   ],
   "source": [
    "# Se crea un arreglo de 1 a 20\n",
    "np.random.seed(1)\n",
    "\n",
    "# Impresión de arreglo y muestreo aleatorio\n",
    "nums = np.arange(1, 21)\n",
    "print('Arreglo:', nums)\n",
    "print('Muestreo aleatorio: ', np.random.choice(a=nums, size=20, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3582, 3454, 1346, ..., 3447, 4777, 2770]),\n",
       " array([4620, 2546,  261, ...,  720, 2868, 4917]),\n",
       " array([5307,  594,  925, ...,  615, 1490, 3208]),\n",
       " array([4288, 2101, 4399, ..., 3458, 5177, 5219]),\n",
       " array([3131, 3822, 2323, ..., 5651,  600, 1805]),\n",
       " array([ 138, 1400,  803, ..., 2648, 4349, 5664]),\n",
       " array([5238,  630,  273, ..., 4814, 5828,  881]),\n",
       " array([2123, 4123, 5343, ..., 1651, 4474, 5586]),\n",
       " array([ 746, 4683,  513, ...,  710, 3553, 2096]),\n",
       " array([2467, 5108, 5052, ..., 3728, 5389, 4002])]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de 10 muestras de bootstrap \n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>http://mashable.com/2013/07/11/pebble-pre-orde...</td>\n",
       "      <td>546.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.535652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747720</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.266546</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>http://mashable.com/2013/06/05/cody-the-scream...</td>\n",
       "      <td>582.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.701950</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.301786</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>http://mashable.com/2014/07/08/apple-posts-beh...</td>\n",
       "      <td>184.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0.577703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.369161</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>http://mashable.com/2013/04/22/thad-starner-go...</td>\n",
       "      <td>626.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>0.324211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.217754</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>http://mashable.com/2013/07/26/tsa-cut-airport...</td>\n",
       "      <td>531.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>http://mashable.com/2014/12/12/cia-torture-rep...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0.576119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.293750</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>http://mashable.com/2013/01/18/digital-natives...</td>\n",
       "      <td>720.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629008</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.355794</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>http://mashable.com/2014/11/18/millennial-rebu...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.206250</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>http://mashable.com/2013/06/20/chime/</td>\n",
       "      <td>567.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.469244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.606648</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.304990</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>http://mashable.com/2014/03/03/samsung-chromeb...</td>\n",
       "      <td>311.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>0.529655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667351</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.329365</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  timedelta  \\\n",
       "3582  http://mashable.com/2013/07/11/pebble-pre-orde...      546.0   \n",
       "3454  http://mashable.com/2013/06/05/cody-the-scream...      582.0   \n",
       "1346  http://mashable.com/2014/07/08/apple-posts-beh...      184.0   \n",
       "4060  http://mashable.com/2013/04/22/thad-starner-go...      626.0   \n",
       "5218  http://mashable.com/2013/07/26/tsa-cut-airport...      531.0   \n",
       "...                                                 ...        ...   \n",
       "2938  http://mashable.com/2014/12/12/cia-torture-rep...       24.0   \n",
       "3462  http://mashable.com/2013/01/18/digital-natives...      720.0   \n",
       "3447  http://mashable.com/2014/11/18/millennial-rebu...       50.0   \n",
       "4777              http://mashable.com/2013/06/20/chime/      567.0   \n",
       "2770  http://mashable.com/2014/03/03/samsung-chromeb...      311.0   \n",
       "\n",
       "      n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "3582             8.0             588.0         0.535652               1.0   \n",
       "3454            12.0             585.0         0.533448               1.0   \n",
       "1346            10.0             301.0         0.577703               1.0   \n",
       "4060            10.0            1909.0         0.324211               1.0   \n",
       "5218             7.0              95.0         0.829787               1.0   \n",
       "...              ...               ...              ...               ...   \n",
       "2938            11.0             345.0         0.576119               1.0   \n",
       "3462            12.0            1215.0         0.410448               1.0   \n",
       "3447            14.0             814.0         0.445545               1.0   \n",
       "4777            10.0             600.0         0.469244               1.0   \n",
       "2770            13.0             762.0         0.529655               1.0   \n",
       "\n",
       "      n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "3582                  0.747720       20.0             1.0       1.0  ...   \n",
       "3454                  0.701950        9.0             4.0       0.0  ...   \n",
       "1346                  0.710526        5.0             1.0       3.0  ...   \n",
       "4060                  0.561688        2.0             2.0       1.0  ...   \n",
       "5218                  0.909091        3.0             1.0       0.0  ...   \n",
       "...                        ...        ...             ...       ...  ...   \n",
       "2938                  0.774510        8.0             2.0       2.0  ...   \n",
       "3462                  0.629008       14.0             7.0       1.0  ...   \n",
       "3447                  0.695652        5.0             2.0       3.0  ...   \n",
       "4777                  0.606648       24.0             1.0      10.0  ...   \n",
       "2770                  0.667351       39.0             6.0      16.0  ...   \n",
       "\n",
       "      min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "3582               0.100000                    0.6              -0.266546   \n",
       "3454               0.033333                    1.0              -0.301786   \n",
       "1346               0.100000                    0.5              -0.369161   \n",
       "4060               0.033333                    1.0              -0.217754   \n",
       "5218               0.100000                    0.5              -0.666667   \n",
       "...                     ...                    ...                    ...   \n",
       "2938               0.100000                    0.7              -0.293750   \n",
       "3462               0.033333                    1.0              -0.355794   \n",
       "3447               0.033333                    0.6              -0.206250   \n",
       "4777               0.100000                    1.0              -0.304990   \n",
       "2770               0.100000                    1.0              -0.329365   \n",
       "\n",
       "      min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "3582              -0.600000              -0.050000            0.000000   \n",
       "3454              -0.750000              -0.050000            0.550000   \n",
       "1346              -1.000000              -0.050000            0.000000   \n",
       "4060              -0.700000              -0.050000            0.500000   \n",
       "5218              -0.666667              -0.666667            0.750000   \n",
       "...                     ...                    ...                 ...   \n",
       "2938              -0.800000              -0.125000            0.400000   \n",
       "3462              -1.000000              -0.100000            0.233333   \n",
       "3447              -0.750000              -0.033333            0.400000   \n",
       "4777              -0.600000              -0.071429            0.000000   \n",
       "2770              -0.600000              -0.155556            0.250000   \n",
       "\n",
       "      title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "3582                  0.000000                0.500000   \n",
       "3454                 -0.250000                0.050000   \n",
       "1346                  0.000000                0.500000   \n",
       "4060                  0.500000                0.000000   \n",
       "5218                 -0.375000                0.250000   \n",
       "...                        ...                     ...   \n",
       "2938                  0.195833                0.100000   \n",
       "3462                  0.066667                0.266667   \n",
       "3447                  0.200000                0.100000   \n",
       "4777                  0.000000                0.500000   \n",
       "2770                  0.650000                0.250000   \n",
       "\n",
       "      abs_title_sentiment_polarity  Popular  \n",
       "3582                      0.000000        1  \n",
       "3454                      0.250000        0  \n",
       "1346                      0.000000        1  \n",
       "4060                      0.500000        1  \n",
       "5218                      0.375000        0  \n",
       "...                            ...      ...  \n",
       "2938                      0.195833        0  \n",
       "3462                      0.066667        1  \n",
       "3447                      0.200000        0  \n",
       "4777                      0.000000        0  \n",
       "2770                      0.650000        0  \n",
       "\n",
       "[6000 rows x 61 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización muestra boostrap #1 para entremiento\n",
    "train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'http://mashable.com/2013/07/11/pebble-pre-order-updates/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34220/3019843604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtreereg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreereg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDOUBLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# Check parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'http://mashable.com/2013/07/11/pebble-pre-order-updates/'"
     ]
    }
   ],
   "source": [
    "# Construcción un árbol de decisión para cada muestra boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Definición del modelo usando DecisionTreeRegressor de sklearn\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame para guardar las predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# Entrenamiento de un árbol sobre cada muestra boostrap y predicción sobre los datos de test\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = train.iloc[sample, 1:]\n",
    "    y_train = train.iloc[sample, 0]\n",
    "    treereg.fit(X_train, y_train)\n",
    "    y_pred.iloc[:,i] = treereg.predict(X_test)\n",
    "    \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3621\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3622\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34220/4063186120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0merrorRegLog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mprediccionesRegLog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0merrorRegLog\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MIAD\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3622\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3623\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3624\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3625\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#### Utilicen este espacio para escribir los códigos del procedimiento del punto 5 ####\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "clfRegLog= LogisticRegression(random_state=0,max_iter=10000)\n",
    "clfRegLog.fit(X_train,y_train)\n",
    "\n",
    "prediccionesRegLog=clfRegLog.predict(X_test)\n",
    "prediccionesProbRegLog=clfRegLog.predict_proba(X_test)\n",
    "\n",
    "errorRegLog=0\n",
    "for i in range(0,len(y_test)):\n",
    "    if(y_test[i]!=prediccionesRegLog[i]):\n",
    "        errorRegLog+=1/len(y_test)\n",
    "        \n",
    "print('El error de clasificación para la regresión logística en la muestra de test es:')\n",
    "print(errorRegLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Votación Mayoritaria\n",
    "En la celda 7 elabore un esamble con la metodología de **Votación mayoritaria** compuesto por 300 muestras bagged para cada uno de los siguientes escenarios:\n",
    "\n",
    "-100 árboles de decisión donde max_depth = None\\\n",
    "-100 árboles de decisión donde max_depth = 2\\\n",
    "-100 regresiones logísticas\n",
    "\n",
    "Evalúe los modelos utilizando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.784, 0.624, 0.558, ..., 0.562, 0.43 , 0.256])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenemiento del modelo con set de entrenamiento y predicción en el set de test\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46546251979437975"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo del error del modelo\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora bagging manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de 100 muestras de bootstrap\n",
    "n_estimators = 100\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 con Max Depth none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de 100 modelos con las 100 muestras boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "1782   1   1   1   1   0   1   1   1   1   1  ...   1   1   0   1   0   0   0   \n",
       "3917   0   1   0   0   0   1   1   0   0   1  ...   1   0   1   0   0   1   0   \n",
       "221    1   1   0   0   1   0   0   1   0   0  ...   0   1   0   0   0   0   1   \n",
       "2135   0   0   0   0   0   0   1   0   0   1  ...   0   0   1   0   0   1   0   \n",
       "5224   1   0   1   1   0   0   1   0   1   0  ...   1   0   0   0   1   0   0   \n",
       "\n",
       "      97  98  99  \n",
       "1782   1   1   0  \n",
       "3917   0   0   1  \n",
       "221    0   1   1  \n",
       "2135   0   0   0  \n",
       "5224   0   0   1  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción para los datos del set de test con cada modelo\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782    62\n",
       "3917    45\n",
       "221     44\n",
       "2135    22\n",
       "5224    27\n",
       "1168    40\n",
       "879     18\n",
       "156     25\n",
       "1657    62\n",
       "323     23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión de la cantidad de modelos que predijeron 1 para 10 observaciones\n",
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votación mayoritaria\n",
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6498015873015873"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desempeño al hacer votación mayoritaria\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6434343434343435"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desempeño al hacer votación mayoritaria\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora con SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6341212744090441, 0.6404040404040404)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 con max depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de 100 muestras de bootstrap\n",
    "n_estimators = 100\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de 100 modelos con las 100 muestras boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=2, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "1782   1   1   0   1   1   0   1   1   1   1  ...   0   1   1   0   1   0   1   \n",
       "3917   1   1   0   0   0   1   0   0   0   1  ...   1   0   1   0   0   1   1   \n",
       "221    1   1   0   1   1   0   0   0   1   0  ...   0   0   1   0   1   0   1   \n",
       "2135   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "5224   0   0   0   1   1   0   0   0   1   0  ...   0   0   0   0   1   0   0   \n",
       "\n",
       "      97  98  99  \n",
       "1782   0   1   0  \n",
       "3917   0   0   1  \n",
       "221    0   0   0  \n",
       "2135   1   1   0  \n",
       "5224   0   0   0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción para los datos del set de test con cada modelo\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782    55\n",
       "3917    62\n",
       "221     33\n",
       "2135     7\n",
       "5224    17\n",
       "1168    15\n",
       "879      0\n",
       "156      2\n",
       "1657    75\n",
       "323     18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión de la cantidad de modelos que predijeron 1 para 10 observaciones\n",
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6341212744090441, 0.6404040404040404)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Votación Ponderada\n",
    "En la celda 8 elabore un ensamble con la metodología de **Votación ponderada** compuesto por 300 muestras bagged para los mismos tres escenarios del punto 7. Evalúe los modelos utilizando las métricas de Accuracy y F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6495049504950494, 0.646)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 8\n",
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=300, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 9 - Comparación y análisis de resultados\n",
    "En la celda 9 comente sobre los resultados obtenidos con las metodologías usadas en los puntos 7 y 8, compare los resultados y enuncie posibles ventajas o desventajas de cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celda 9\n",
    "Para el caso y aun variando la profundidad el resultado del accurancy y f1 score son similares (practicamente iguales), sin embargo, para este\n",
    "modelo la precision \"Accurancy fue muy baja\"\n",
    "\n",
    "A pesar de ser un modelo de ensamblaje la precision fue muy baja para ambos metodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
